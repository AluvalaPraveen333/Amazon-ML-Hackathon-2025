{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLLthZ6CtHKEOuk9cNzgjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munnurumahesh03-coder/Amazon-ML-Hackathon-2025/blob/main/Model_Gauntlet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UXNmn9SFlbn"
      },
      "source": [
        "# **Importings**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehb_XmdlFk70",
        "outputId": "b617b423-ed91-40b5-f6dc-fe6e33ed1c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 1.1: Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 1: PROJECT SETUP\n",
        "# =============================================================================\n",
        "\n",
        "# -- 1.1: Import Libraries --\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import hstack\n",
        "import lightgbm as lgb\n",
        "\n",
        "print(\"Section 1.1: Libraries imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm3cSCgOFk3r",
        "outputId": "ba9b81fc-1f59-4ad1-bd50-bb553988dd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 1.2: File paths defined.\n",
            "Train file is set to: train.csv\n",
            "Test file is set to: test.csv\n"
          ]
        }
      ],
      "source": [
        "# -- 1.2: Define File Paths --\n",
        "# IMPORTANT: Please update these paths to the correct location of your files.\n",
        "TRAIN_FILE_PATH = \"train.csv\"  # <--- EDIT THIS PATH\n",
        "TEST_FILE_PATH = \"test.csv\"    # <--- EDIT THIS PATH\n",
        "\n",
        "print(\"Section 1.2: File paths defined.\")\n",
        "print(f\"Train file is set to: {TRAIN_FILE_PATH}\")\n",
        "print(f\"Test file is set to: {TEST_FILE_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ3JZr55Fk03",
        "outputId": "6ad1a7eb-632a-481e-d41f-a55b2b99e659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 1.3: Data loaded successfully.\n",
            "Training data shape: (75000, 4)\n",
            "Test data shape: (75000, 3)\n",
            "\n",
            "First 3 rows of training data:\n",
            "   sample_id  \\\n",
            "0      33127   \n",
            "1     198967   \n",
            "2     261251   \n",
            "\n",
            "                                                                                       catalog_content  \\\n",
            "0       Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Fl Oz\\n   \n",
            "1  Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\\nBullet Point 1: Or...   \n",
            "2  Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\\nBullet ...   \n",
            "\n",
            "                                            image_link  price  \n",
            "0  https://m.media-amazon.com/images/I/51mo8htwTHL.jpg   4.89  \n",
            "1  https://m.media-amazon.com/images/I/71YtriIHAAL.jpg  13.12  \n",
            "2  https://m.media-amazon.com/images/I/51+PFEe-w-L.jpg   1.97  \n"
          ]
        }
      ],
      "source": [
        "# -- 1.3: Load Datasets --\n",
        "try:\n",
        "    train_df = pd.read_csv(TRAIN_FILE_PATH)\n",
        "    test_df = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "    print(\"Section 1.3: Data loaded successfully.\")\n",
        "    print(f\"Training data shape: {train_df.shape}\")\n",
        "    print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "    # Display the first few rows to verify\n",
        "    print(\"\\nFirst 3 rows of training data:\")\n",
        "    pd.set_option('display.max_colwidth', 100)\n",
        "    print(train_df.head(3))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\n---\")\n",
        "    print(\"ERROR in Section 1.3: Data files not found.\")\n",
        "    print(f\"Please check if the paths defined in the previous cell are correct.\")\n",
        "    print(\"---\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred in Section 1.3: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwoctbX-Fkxf",
        "outputId": "8b96ba64-278e-4c9f-be29-7e370301e45d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 1.4: SMAPE function defined successfully.\n",
            "\n",
            "--- Section 1 Complete ---\n"
          ]
        }
      ],
      "source": [
        "# -- 1.4: Define Evaluation Metric --\n",
        "def smape(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
        "    A small epsilon is added to the denominator to avoid division by zero.\n",
        "    \"\"\"\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    return np.mean(numerator / (denominator + 1e-8)) * 100\n",
        "\n",
        "print(\"Section 1.4: SMAPE function defined successfully.\")\n",
        "print(\"\\n--- Section 1 Complete ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s8nt809chrY",
        "outputId": "f9322f22-f3e1-4220-bb37-d3e02a02e4f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sample_id  \\\n",
              "0          33127   \n",
              "1         198967   \n",
              "2         261251   \n",
              "3          55858   \n",
              "4         292686   \n",
              "...          ...   \n",
              "74995      41424   \n",
              "74996      35537   \n",
              "74997     249971   \n",
              "74998     188322   \n",
              "74999     298504   \n",
              "\n",
              "                                                                                           catalog_content  \\\n",
              "0           Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Fl Oz\\n   \n",
              "1      Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\\nBullet Point 1: Or...   \n",
              "2      Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\\nBullet ...   \n",
              "3      Item Name: Judee’s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings an...   \n",
              "4      Item Name: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\\nBullet Point: kedem Sherry Cook...   \n",
              "...                                                                                                    ...   \n",
              "74995  Item Name: ICE BREAKERS Spearmint Sugar Free Mints Tins, 1.5 oz (8 Count)\\nBullet Point 1: Conta...   \n",
              "74996  Item Name: Davidson's Organics, Vanilla Essence, 100-count Individually Wrapped Tea Bags\\nBullet...   \n",
              "74997  Item Name: Jolly Rancher Hard Candy - Blue Raspberry - 5 Pound Resealable Bag\\nProduct Descripti...   \n",
              "74998  Item Name: Nescafe Dolce Gusto Capsules - CARAMEL MACCHIATO, 16 Pods\\nBullet Point 1: Nescafe Do...   \n",
              "74999  Item Name: Pimenton de la Vera - Picante (2.47 ounce)\\nBullet Point 1: No hydrogenated fats or h...   \n",
              "\n",
              "                                                image_link   price  \n",
              "0      https://m.media-amazon.com/images/I/51mo8htwTHL.jpg   4.890  \n",
              "1      https://m.media-amazon.com/images/I/71YtriIHAAL.jpg  13.120  \n",
              "2      https://m.media-amazon.com/images/I/51+PFEe-w-L.jpg   1.970  \n",
              "3      https://m.media-amazon.com/images/I/41mu0HAToDL.jpg  30.340  \n",
              "4      https://m.media-amazon.com/images/I/41sA037+QvL.jpg  66.490  \n",
              "...                                                    ...     ...  \n",
              "74995  https://m.media-amazon.com/images/I/81p9PcPsffL.jpg  10.395  \n",
              "74996  https://m.media-amazon.com/images/I/51DDKoa+mbL.jpg  35.920  \n",
              "74997  https://m.media-amazon.com/images/I/91R2XCcpUfL.jpg  50.330  \n",
              "74998  https://m.media-amazon.com/images/I/51W40YU98+L.jpg  15.275  \n",
              "74999  https://m.media-amazon.com/images/I/81dFnrP6C4L.jpg  28.240  \n",
              "\n",
              "[75000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a85e7e7a-e06d-48da-b24a-b4bcc35f27d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>catalog_content</th>\n",
              "      <th>image_link</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33127</td>\n",
              "      <td>Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Fl Oz\\n</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51mo8htwTHL.jpg</td>\n",
              "      <td>4.890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198967</td>\n",
              "      <td>Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\\nBullet Point 1: Or...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/71YtriIHAAL.jpg</td>\n",
              "      <td>13.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>261251</td>\n",
              "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\\nBullet ...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-L.jpg</td>\n",
              "      <td>1.970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55858</td>\n",
              "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings an...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/41mu0HAToDL.jpg</td>\n",
              "      <td>30.340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>292686</td>\n",
              "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\\nBullet Point: kedem Sherry Cook...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/41sA037+QvL.jpg</td>\n",
              "      <td>66.490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74995</th>\n",
              "      <td>41424</td>\n",
              "      <td>Item Name: ICE BREAKERS Spearmint Sugar Free Mints Tins, 1.5 oz (8 Count)\\nBullet Point 1: Conta...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/81p9PcPsffL.jpg</td>\n",
              "      <td>10.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74996</th>\n",
              "      <td>35537</td>\n",
              "      <td>Item Name: Davidson's Organics, Vanilla Essence, 100-count Individually Wrapped Tea Bags\\nBullet...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51DDKoa+mbL.jpg</td>\n",
              "      <td>35.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74997</th>\n",
              "      <td>249971</td>\n",
              "      <td>Item Name: Jolly Rancher Hard Candy - Blue Raspberry - 5 Pound Resealable Bag\\nProduct Descripti...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/91R2XCcpUfL.jpg</td>\n",
              "      <td>50.330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74998</th>\n",
              "      <td>188322</td>\n",
              "      <td>Item Name: Nescafe Dolce Gusto Capsules - CARAMEL MACCHIATO, 16 Pods\\nBullet Point 1: Nescafe Do...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51W40YU98+L.jpg</td>\n",
              "      <td>15.275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74999</th>\n",
              "      <td>298504</td>\n",
              "      <td>Item Name: Pimenton de la Vera - Picante (2.47 ounce)\\nBullet Point 1: No hydrogenated fats or h...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/81dFnrP6C4L.jpg</td>\n",
              "      <td>28.240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a85e7e7a-e06d-48da-b24a-b4bcc35f27d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a85e7e7a-e06d-48da-b24a-b4bcc35f27d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a85e7e7a-e06d-48da-b24a-b4bcc35f27d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86079204-dcdf-4a8d-bc30-73288c95b409\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86079204-dcdf-4a8d-bc30-73288c95b409')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86079204-dcdf-4a8d-bc30-73288c95b409 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_85042ba1-7d35-488f-aeda-c40281ab6449\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_85042ba1-7d35-488f-aeda-c40281ab6449 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 75000,\n  \"fields\": [\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86585,\n        \"min\": 0,\n        \"max\": 299438,\n        \"num_unique_values\": 75000,\n        \"samples\": [\n          158784,\n          4095,\n          172021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"catalog_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74900,\n        \"samples\": [\n          \"Item Name: Cooper Street Granola Bakes - Chewy Breakfast Granola Bars with Chia, Flax, Buckwheat and Oats - Blueberry Pomegranate Individually Wrapped Nut & Dairy Free On-The-Go or School Snacks - 12 Bars, 1oz each\\nBullet Point 1: Cookies, Made Better - Fuel your day and enjoy delectably chewy goodness with Cooper Street Granola Bars Bulk! Bite into wholesome and healthful ingredients like chia, flax, buckwheat and oats and get off on the right foot with our healthy snack bars!\\nBullet Point 2: Blueberry Pomegranate Flavor - Bursting with locally sourced Michigan blueberries and blended with a pomegranate's pop, our granola snack bars deliver the perfect mix of sweet and tart. Pomegranates and blueberries truly are a match made in heaven!\\nBullet Point 3: Guilt-Free Deliciousness - Start your day on a high note with the energy you need with this pomegranate blueberry bar. Our satiating anytime breakfast cookies individually wrapped satisfy your sweet tooth with high-quality ingredients, for a truly clean and honest energy boost throughout your day!\\nBullet Point 4: Baked With Care - Made with a mix of passion, all natural ingredients and 100 years of tradition, our healthy granola bar is still handmade in our family-run Michigan bakery. Our perfect pick me up is baked to a moist and chewy perfection.\\nBullet Point 5: Enjoyed By All - We go the extra mile to ensure everyone can enjoy our granola soft baked cookies. Made in a dedicated peanut free facility to be dairy free, HFCS free, tans fat free, soy free, artificial flavourings free and also low in sodium. We don't tolerate any nasties!\\nProduct Description: individual snacks breakfast foods individually wrapped breakfast food breakfast snacks individually wrapped granola snacks individual packs healthy bars for kids bars healthy granola bars for kids granola bars kids bars kids granola bars healthy organic kids snacks kids granola bars kids bar organic granola bars snack bars for kids kid bars healthy snacks for kids granola bars variety packs breakfast bars healthy snack bars healthy food bars nut free bars granola bars soft grabola bars granila bars grnola bars granola bara gronala bars gronalla bars individually wrapped breakfast items good snacks for kids granola bar packs kids breakfast bars healthy snacks for kids individually wrapped bars food copper street blueberry pomegranate cookie cooper street cookie blueberry pomegranate cooper street blueberry pomegrante pomegranate blueberry bar cooper street blueberry pomegranate granola cookie bakes cooper street cookies blueberry pomegranate bakes blurberry pomegranit granola cooper street pomegranate blueberry pomogranite granola bake blueberry pomogranate bars blueberry pomegranate granola cookie blueberry and pomegranate granola bar cooper st blueberry pomegranite granola bar cooper st blueberry pomegrante bars blueberry pomegrenate cooper street cooper street blueberry pomegranite cooper street blueberry pomegrante bar copper street granola bar - blueberry pomegranate blueberry pomegranate granola cookie bake blueberry pomegranate granola bakes 12-count (1 oz or 2 oz) pomegranate blueberry snack cooper street snacks blueberry pom cooper street cookies chewy granola bakes blueberry pomegranate 1... cooper farms blueberry pomegranate bars blueberry pomegranate granola bakes blueberry pomegranate granola bars blueberry pomegranate granola bar pomegranate pomegranate snacks 1 ounce - 12 per case cooper street granola cookie bakes blueberry pomegranate blueberry pomegranate bar blueberry pomegranate bars cooper street blueberry pomegranate granola cookie bake\\nValue: 12.0\\nUnit: Ounce\\n\",\n          \"Item Name: Stonewall Kitchen Wildflower Honey, 16 Ounces\\nBullet Point 1: Stonewall Kitchen Wildflower Honey, 16 Ounces\\nBullet Point 2: Our Wildflower Honey is a delicious and unique blend of nectars gathered from a variety of flowering trees, shrubs and flowers\\nBullet Point 3: A delectably sweet, medium flavored honey with floral notes\\nBullet Point 4: Perfect for sweetening tea, enjoying on pancakes or for adding wonderful flavor to baked goods\\nBullet Point 5: Stonewall Kitchen Family of Brands: Our award winning line of gourmet food, home goods, and gifts are loved around the world. Featuring brands such as Legal Sea Foods, Michel Design Works, Montebello, Napa Valley Naturals, Stonewall Home, Stonewall Kitchen, Urban Accents, Vermont Coffee Company, Vermont Village, and Village Candle\\nBullet Point 6: About Us: It all started in 1991 at a local farmers' market with a few dozen items that we'd finished hand-labeling only hours before. Fast-forward to today and Stonewall Kitchen is now home to an ever-growing family of like-minded lifestyle brands! Expertly made with premium ingredients, our products are the result of decades spent dreaming up, testing and producing only the very best in specialty foods and fine home living.\\nValue: 16.0\\nUnit: Ounce\\n\",\n          \"Item Name: Quaker Large Rice Cakes, Lightly Salted, Pack of 6\\nBullet Point 1: Made with whole grain brown rice and baked to crispy deliciousness\\nBullet Point 2: Enjoy plain or top with your own peanut butter, jelly, or jam. Great for any snacking occasion\\nBullet Point 3: 35 calories per cake\\nBullet Point 4: The perfect amount of crunch, with the taste of salt\\nValue: 26.82\\nUnit: Ounce\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 72288,\n        \"samples\": [\n          \"https://m.media-amazon.com/images/I/81x1QmnBG-L.jpg\",\n          \"https://m.media-amazon.com/images/I/81MWCBM09NL.jpg\",\n          \"https://m.media-amazon.com/images/I/91X0Abm9cGL.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.37693218315522,\n        \"min\": 0.13,\n        \"max\": 2796.0,\n        \"num_unique_values\": 11862,\n        \"samples\": [\n          22.075,\n          15.69,\n          55.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1crmbBzLHw0"
      },
      "source": [
        "# **EDA**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqgSLJAoAbBq",
        "outputId": "72bfc9bf-7f3d-4280-d221-5e9dc0dc1a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Section 2: Targeted EDA on 'catalog_content'...\n",
            "Objective: To discover patterns for brand, weight, volume, and other keywords before extraction.\n",
            "\n",
            "Combined DataFrame created for EDA with shape: (150000, 4)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 2: EXPLORATORY DATA ANALYSIS (EDA) FOR FEATURE ENGINEERING\n",
        "# =============================================================================\n",
        "\n",
        "# -- 2.1: Objective and Setup --\n",
        "\n",
        "print(\"Starting Section 2: Targeted EDA on 'catalog_content'...\")\n",
        "print(\"Objective: To discover patterns for brand, weight, volume, and other keywords before extraction.\")\n",
        "\n",
        "# Combine train and test for a complete overview of text patterns.\n",
        "# This ensures we capture patterns present in either dataset.\n",
        "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# For this EDA, it's helpful to see the full text content\n",
        "pd.set_option('display.max_colwidth', 300)\n",
        "\n",
        "print(f\"\\nCombined DataFrame created for EDA with shape: {combined_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNN6-axMAjo3",
        "outputId": "3aec014d-17d0-4b85-a9ed-1539a4b65e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for all number-unit patterns in the dataset...\n",
            "\n",
            "Discovered 5230 unique potential units.\n",
            "Here is the complete list:\n",
            "['a', 'aa', 'aaa', 'aang', 'ab', 'abalone', 'abbey', 'about', 'above', 'abv', 'ac', 'acaciaware', 'acai', 'access', 'accolades', 'accredited', 'accuracy', 'ace', 'aceto', 'ach', 'acidity', 'acidophilus', 'acids', 'acne', 'acordeon', 'acorns', 'acre', 'acres', 'across', 'action', 'active', 'activities', 'activity', 'actual', 'ad', 'adam', 'adams', 'adapter', 'adaptogen', 'adaptogenic', 'adaptogens', 'add', 'added', 'addiction', 'addictive', 'additional', 'additionally', 'additions', 'additives', 'adds', 'adhesive', 'adi', 'adorable', 'adorably', 'adult', 'adults', 'adv', 'advanced', 'advantix', 'advil', 'affordable', 'after', 'aftertaste', 'agar', 'aged', 'ahmad', 'air', 'airbrush', 'airheads', 'airlume', 'airtight', 'airwaves', 'aka', 'ala', 'alamo', 'alarm', 'album', 'alc', 'alcohol', 'ale', 'alessi', 'alfajores', 'alfredo', 'alien', 'alkaline', 'alkalizing', 'alkane', 'alkyl', 'all', 'allergen', 'allergens', 'allergensthis', 'allergist', 'allergn', 'allergy', 'alligator', 'allow', 'allows', 'allure', 'almond', 'almonds', 'alocacia', 'aloe', 'along', 'alpha', 'alphabet', 'alphabetic', 'alpina', 'alpine', 'alpineaire', 'already', 'also', 'alternative', 'aluminium', 'aluminum', 'always', 'am', 'amaretto', 'amazing', 'amber', 'america', 'american', 'americans', 'americolor', 'amino', 'amki', 'ammhurric', 'amnio', 'among', 'amor', 'amount', 'amp', 'amphitheaters', 'amt', 'amy', 'an', 'anahuac', 'anchovies', 'ancient', 'and', 'andno', 'anemonas', 'anemone', 'anemones', 'angel', 'animal', 'animals', 'annual', 'anointing', 'anos', 'another', 'antacid', 'anti', 'antioxidant', 'antioxidants', 'anything', 'anywhere', 'apostles', 'appa', 'apparent', 'appetite', 'apple', 'apples', 'applewood', 'application', 'applications', 'applicators', 'apply', 'approved', 'approx', 'approximately', 'apricot', 'april', 'apron', 'aqua', 'arabica', 'arabicas', 'arbordoun', 'arctic', 'are', 'aria', 'arizona', 'armour', 'aroma', 'aromatic', 'aron', 'arrabbiatta', 'arrange', 'arrow', 'arrowroot', 'art', 'artesian', 'artichokes', 'artificial', 'artificially', 'artisan', 'artisanal', 'as', 'aseptic', 'ashwagandha', 'asian', 'asking', 'aspartame', 'assembled', 'assorted', 'assortment', 'assortments', 'asst', 'asta', 'astles', 'astro', 'at', 'attaining', 'attractant', 'atunes', 'au', 'audio', 'australian', 'authentic', 'authentically', 'autumnal', 'availability', 'available', 'ave', 'avenue', 'average', 'avg', 'avocado', 'avocados', 'award', 'awarded', 'awards', 'away', 'awesome', 'axe', 'ayurvedic', 'az', 'b', 'ba', 'baby', 'babyruth', 'bach', 'backwoods', 'bacon', 'badass', 'bag', 'bagasse', 'bagcelebration', 'bagcountry', 'bagels', 'bagpack', 'bags', 'bagsflavororangetypeelectrolyte', 'bagss', 'bahamian', 'bake', 'baked', 'baker', 'bakerschocolate', 'bakery', 'bakerysupplies', 'baking', 'baklava', 'balance', 'balanced', 'ball', 'ballard', 'ballerina', 'ballparks', 'ballpoint', 'balls', 'balsamic', 'balsmic', 'bamboo', 'banana', 'bananas', 'banderitas', 'banks', 'banned', 'bar', 'barbecue', 'barbeque', 'barcode', 'bargains', 'barista', 'barley', 'barq', 'barr', 'barrel', 'barrels', 'bars', 'barsper', 'base', 'baseball', 'basic', 'basics', 'basil', 'basket', 'basketball', 'batch', 'batches', 'bath', 'bathroom', 'batteries', 'battery', 'bay', 'bays', 'bazooka', 'bbq', 'bc', 'bcaas', 'bce', 'be', 'beaads', 'beach', 'beaches', 'beads', 'bean', 'beanery', 'beans', 'bear', 'bears', 'beat', 'beaten', 'beautiful', 'beautifully', 'beautifying', 'beaver', 'beavertail', 'beaverton', 'bebida', 'because', 'beef', 'beehives', 'beekeepers', 'beer', 'beerrub', 'bees', 'beet', 'before', 'being', 'belgian', 'bell', 'beloved', 'below', 'belt', 'belts', 'beneficial', 'benefits', 'bento', 'berries', 'berry', 'besides', 'best', 'bestseller', 'bestsellers', 'beta', 'better', 'bettergood', 'betty', 'beverage', 'beverages', 'bg', 'bgas', 'bha', 'bible', 'bicolor', 'big', 'bigelow', 'billingtons', 'billiob', 'billion', 'binder', 'bing', 'bingo', 'biodegradable', 'bioengineered', 'biological', 'biologically', 'bionaturae', 'biotin', 'biotypes', 'biplane', 'birria', 'birthday', 'biscotti', 'biscuit', 'biscuits', 'bite', 'bites', 'bitter', 'bitters', 'bk', 'black', 'blackberry', 'blackcurrant', 'blade', 'blades', 'blake', 'blank', 'blast', 'bleach', 'blemish', 'blend', 'blendable', 'blended', 'blends', 'bling', 'blinis', 'blissfully', 'block', 'blocks', 'blonde', 'blondies', 'blood', 'bloody', 'bloom', 'blooms', 'blossoms', 'blow', 'blt', 'blue', 'blueberries', 'blueberry', 'bluey', 'blunt', 'blush', 'bm', 'bn', 'boasting', 'boasts', 'boba', 'bobas', 'bobo', 'bocadin', 'body', 'bodywash', 'boil', 'bold', 'bolsas', 'bolsita', 'bolsitas', 'bon', 'bonn', 'bonsai', 'bonus', 'bookmarks', 'boost', 'booster', 'boosting', 'booth', 'boppin', 'born', 'boston', 'botan', 'botanical', 'botanicals', 'botanics', 'botella', 'botellas', 'bottle', 'bottles', 'bottling', 'bou', 'bouillon', 'bouquet', 'bouquets', 'bourbon', 'bovine', 'bowl', 'bowlin', 'bowls', 'box', 'boxes', 'boxitem', 'boyer', 'boz', 'bp', 'bpa', 'bpz', 'br', 'brach', 'braeburn', 'braided', 'brain', 'bran', 'branches', 'brand', 'branded', 'brands', 'bread', 'breakfast', 'breakfasts', 'breton', 'brew', 'brewer', 'breweries', 'brewers', 'brewing', 'brex', 'brick', 'bridal', 'bride', 'bright', 'brightening', 'brightly', 'brightness', 'bring', 'brings', 'brioche', 'brisk', 'british', 'brix', 'broad', 'broccoli', 'bronze', 'bronzers', 'brooklyn', 'broth', 'brown', 'brownie', 'brownies', 'brush', 'brushes', 'brushings', 'brwn', 'bs', 'bsp', 'btl', 'btls', 'bu', 'bubaloo', 'bubble', 'bubly', 'bucatini', 'bucket', 'buckets', 'buds', 'buff', 'buffalo', 'buffered', 'built', 'bulb', 'bulbs', 'bulk', 'bullet', 'bulletproof', 'bumble', 'bumblebee', 'bun', 'bunch', 'bunches', 'bundle', 'bundled', 'bundles', 'bunnies', 'bunny', 'buns', 'burbusodas', 'burlap', 'burp', 'bursting', 'burt', 'bushels', 'bushes', 'business', 'but', 'butcher', 'butcherbox', 'butter', 'butterfinger', 'butterfly', 'buttermilk', 'buttermints', 'butters', 'butterscotch', 'buttery', 'buttons', 'butyl', 'buy', 'bw', 'bx', 'bxs', 'by', 'c', 'ca', 'cabernet', 'cacao', 'cactus', 'cada', 'cadbury', 'cade', 'caesar', 'cafe', 'caff', 'caffe', 'caffeinated', 'caffeine', 'caffeinenated', 'caja', 'cajas', 'cajuns', 'cake', 'cakes', 'cakesters', 'cal', 'calcium', 'caliente', 'california', 'call', 'calligraphy', 'calls', 'cally', 'calms', 'calo', 'caloires', 'calorie', 'calories', 'caloriesno', 'cals', 'calyx', 'campanile', 'camphor', 'camping', 'camsquare', 'can', 'canadadry', 'canary', 'candied', 'candies', 'candle', 'candles', 'candy', 'cane', 'canel', 'canes', 'canettes', 'canister', 'canisters', 'canned', 'cannels', 'cannisters', 'canola', 'cans', 'cap', 'capa', 'capacity', 'capful', 'capfuls', 'caplets', 'cappuccino', 'capric', 'capriccio', 'caprylic', 'caps', 'capsule', 'capsules', 'capsuleservings', 'captivating', 'caramel', 'caramello', 'caramels', 'caramilk', 'carat', 'carb', 'carbo', 'carbohydrate', 'carbohydrates', 'carbon', 'carbonated', 'carbs', 'carburettor', 'card', 'cardboard', 'cardio', 'cards', 'cardstock', 'care', 'carefully', 'carmela', 'carnival', 'carolies', 'carpenter', 'carpet', 'carrageenan', 'carriage', 'carrot', 'carrots', 'carrs', 'carry', 'carton', 'cartons', 'cartridge', 'case', 'casein', 'cases', 'cashew', 'cashews', 'casings', 'casino', 'casks', 'cat', 'catalyst', 'categories', 'category', 'cauliflower', 'caution', 'cavity', 'cc', 'cd', 'cds', 'celebrating', 'celebration', 'celestial', 'cell', 'cello', 'cellophane', 'celsius', 'celtic', 'cent', 'center', 'centerpieces', 'centimeter', 'centimeters', 'centimetersl', 'centimetres', 'cento', 'cents', 'centuries', 'ceramic', 'cereal', 'cereals', 'certification', 'certifications', 'certified', 'cfm', 'cfr', 'ch', 'chai', 'chakra', 'chakras', 'chamber', 'chamomile', 'champagne', 'champagnottina', 'chanca', 'chance', 'changed', 'characters', 'charcoal', 'charcuterie', 'chardonnay', 'charge', 'charmin', 'charming', 'charms', 'chasing', 'cheap', 'chebe', 'check', 'checkered', 'checkout', 'cheddar', 'cheers', 'cheese', 'cheesecake', 'cheesecloth', 'cheeses', 'cheesy', 'cheetos', 'cheez', 'chef', 'chefmaster', 'chefs', 'chefsbest', 'chemy', 'cherished', 'cherries', 'cherry', 'chesapeake', 'chessmen', 'chestnuts', 'chewable', 'chewables', 'chews', 'chewy', 'chi', 'chia', 'chic', 'chicago', 'chicha', 'chicharrones', 'chick', 'chicken', 'chicks', 'chicory', 'chiditarod', 'childhood', 'children', 'chile', 'chiles', 'chili', 'chilli', 'chimichurri', 'china', 'chinese', 'chip', 'chips', 'chirris', 'chm', 'chock', 'choco', 'chocolate', 'chocolates', 'chocolatey', 'choice', 'cholest', 'cholesterol', 'cholestrol', 'cholula', 'chop', 'chopped', 'chops', 'chopstikcs', 'christmas', 'chse', 'chunk', 'chunky', 'chupa', 'churros', 'cilantro', 'cinnabon', 'cinnamon', 'cioccolato', 'circus', 'citrus', 'ck', 'cl', 'claey', 'claeys', 'clam', 'clamato', 'clams', 'claories', 'class', 'classic', 'claw', 'clay', 'clean', 'cleaning', 'cleanser', 'cleansing', 'clear', 'clearly', 'cleopatra', 'clicks', 'clif', 'climate', 'clings', 'clinical', 'clinically', 'close', 'closed', 'cloth', 'clove', 'clover', 'cloves', 'clr', 'clumping', 'cluster', 'cm', 'cmh', 'cml', 'cmuscle', 'cmw', 'cmweight', 'cn', 'cnt', 'cntrl', 'coa', 'coarse', 'coasters', 'coated', 'cobalt', 'cobs', 'coca', 'cocculus', 'cocktail', 'cocktails', 'cocoa', 'cocomel', 'coconut', 'coconuts', 'cod', 'coenzyme', 'cofactor', 'coffee', 'coffeemakers', 'coffees', 'coffeesock', 'coin', 'coins', 'cokes', 'cola', 'cold', 'collagen', 'collard', 'collardouble', 'collect', 'collectible', 'collection', 'collections', 'college', 'colombian', 'color', 'colored', 'colorful', 'coloring', 'colors', 'colossal', 'com', 'combat', 'combination', 'combinations', 'combine', 'combined', 'combines', 'combining', 'combos', 'comes', 'comfort', 'comfortable', 'comfrtng', 'command', 'commemorative', 'comments', 'commercial', 'committed', 'common', 'commonly', 'commun', 'compact', 'companies', 'company', 'compare', 'compartment', 'compartments', 'compatible', 'competitions', 'competitive', 'competitors', 'complementary', 'complete', 'completely', 'complex', 'compliant', 'complimentary', 'components', 'compostable', 'compounds', 'concentrate', 'concentrated', 'concentrates', 'concentration', 'concerns', 'condiment', 'condiments', 'conditioner', 'conditions', 'condom', 'cone', 'cones', 'confectioners', 'confetti', 'connect', 'conntie', 'consecutive', 'constellation', 'constellations', 'consumer', 'consumers', 'consuming', 'cont', 'container', 'containers', 'containing', 'contains', 'contaminants', 'content', 'contents', 'contest', 'continent', 'continents', 'continue', 'continuous', 'contour', 'contribute', 'contribution', 'control', 'convenience', 'convenient', 'conveniently', 'conversation', 'conversion', 'cook', 'cooked', 'cookie', 'cookies', 'cooking', 'cool', 'cooling', 'cooperative', 'cooperatively', 'cooperatives', 'coordinating', 'copenhagen', 'copper', 'coral', 'cordelyen', 'cordelyne', 'cordial', 'cordyceps', 'cordylines', 'core', 'corinthians', 'corks', 'corn', 'corner', 'cornstar', 'corrosion', 'cosamin', 'cosi', 'costa', 'costillas', 'cotton', 'cou', 'couger', 'cough', 'coun', 'count', 'countare', 'countbrewing', 'countcountry', 'countdown', 'countof', 'countper', 'countq', 'countries', 'country', 'counts', 'countspecifications', 'countswheat', 'counttaste', 'countthese', 'couples', 'course', 'cout', 'cover', 'covered', 'cow', 'cps', 'cr', 'crab', 'crabs', 'cracker', 'crackers', 'craft', 'craftbond', 'crafted', 'cran', 'cranberries', 'cranberry', 'crates', 'crave', 'craveable', 'crayon', 'crazy', 'cream', 'creamer', 'creamers', 'creamy', 'created', 'creates', 'creation', 'creations', 'creative', 'credita', 'creditable', 'creme', 'creole', 'crepes', 'crew', 'cricket', 'crinkle', 'crisp', 'crispbread', 'crispbreads', 'crisps', 'crispy', 'cristal', 'critical', 'croissants', 'crop', 'croutons', 'crown', 'cruelty', 'cruet', 'cruets', 'crumb', 'crunch', 'crunchy', 'crush', 'crushed', 'crust', 'crusts', 'cry', 'cryo', 'crystal', 'crystallized', 'cs', 'csp', 'ct', 'ctmedium', 'ctpack', 'cts', 'cu', 'cube', 'cubes', 'cubic', 'cubitos', 'cucharadita', 'cucharilla', 'cucumber', 'cucumbers', 'culinary', 'cultivated', 'cultural', 'cultured', 'cup', 'cupalmond', 'cupcake', 'cupcakes', 'cuphoney', 'cupping', 'cups', 'cupschocolate', 'cupsugar', 'curcuma', 'curl', 'curls', 'curly', 'currently', 'curry', 'curve', 'cushion', 'custom', 'customer', 'customers', 'customizable', 'customization', 'cut', 'cute', 'cutting', 'cwch', 'cycles', 'd', 'dad', 'dads', 'daily', 'dairy', 'dandelion', 'dandruff', 'danish', 'darjeeling', 'dark', 'darkest', 'darrell', 'dart', 'darts', 'darvilles', 'dashes', 'date', 'dates', 'dave', 'davinci', 'day', 'days', 'daytime', 'dc', 'de', 'dead', 'dear', 'decadent', 'decades', 'decaf', 'decaffeinated', 'decaffeinating', 'decaffeination', 'declicious', 'decorated', 'decorating', 'decorations', 'decorative', 'decorator', 'dedicated', 'deep', 'deeply', 'deer', 'defects', 'defender', 'defenders', 'defining', 'deg', 'degree', 'degreef', 'degrees', 'degress', 'del', 'delectable', 'delecteable', 'delicate', 'delicious', 'deliciously', 'delicitaly', 'delight', 'delightful', 'delightfully', 'delights', 'delish', 'delivers', 'deluxe', 'demerara', 'denier', 'dennymike', 'dense', 'dentist', 'dentists', 'denture', 'deodorant', 'depending', 'der', 'derived', 'dermatologist', 'description', 'desi', 'designation', 'designed', 'designs', 'desire', 'despite', 'dessert', 'desserts', 'detailed', 'detergent', 'detoxification', 'detroit', 'devilishly', 'dextrose', 'dgari', 'dha', 'di', 'dia', 'diabetes', 'diabetic', 'dial', 'diameter', 'diamond', 'diaper', 'diapers', 'dias', 'dice', 'did', 'die', 'dieffenbacha', 'diente', 'diet', 'dietary', 'diets', 'difference', 'different', 'difficulty', 'digging', 'digital', 'digits', 'dijon', 'dilis', 'dill', 'dimension', 'dimensions', 'ding', 'dinner', 'dioxane', 'dip', 'dipped', 'dipping', 'dipt', 'directions', 'disc', 'discard', 'disciples', 'discount', 'discovered', 'discs', 'diseases', 'dish', 'dishes', 'dishwasher', 'disinfecting', 'disney', 'dispenser', 'dispensers', 'dispensing', 'display', 'displays', 'disposable', 'dispose', 'dissolve', 'dissolves', 'distillers', 'distinct', 'distinctive', 'distinctly', 'distinguished', 'distribution', 'diverse', 'divide', 'dividers', 'divine', 'dixie', 'diy', 'diya', 'dl', 'do', 'doctor', 'doctors', 'documented', 'dog', 'dogs', 'dollar', 'dollars', 'don', 'donated', 'donation', 'donettes', 'donut', 'donuts', 'door', 'doors', 'doritos', 'dos', 'dosas', 'dose', 'doses', 'dots', 'double', 'dough', 'dove', 'down', 'doz', 'dozen', 'dp', 'dpsg', 'dr', 'draft', 'drag', 'dragon', 'dragons', 'drain', 'drake', 'dram', 'drawer', 'drawers', 'dreadful', 'dressing', 'dressings', 'dried', 'drilled', 'drink', 'drinking', 'drinks', 'dripper', 'drop', 'droppers', 'drops', 'drpepper', 'drs', 'drunken', 'dry', 'dryer', 'drying', 'ds', 'dual', 'dubble', 'ducal', 'duck', 'due', 'duke', 'dulce', 'dulcet', 'dulcolax', 'dum', 'dunk', 'dunkin', 'dunking', 'duo', 'durable', 'during', 'dusters', 'dvd', 'dvds', 'dx', 'dye', 'dynamite', 'dynamo', 'dz', 'e', 'ea', 'each', 'eachbottle', 'eaches', 'eachto', 'ear', 'earl', 'early', 'earth', 'earthboundfarm', 'ease', 'easeout', 'easily', 'easter', 'eastern', 'easy', 'eat', 'eatable', 'eatdelcorazon', 'eaters', 'ech', 'eco', 'ecofriendly', 'edge', 'edible', 'edition', 'educational', 'edward', 'ee', 'eelicious', 'efa', 'efas', 'effect', 'effective', 'effects', 'effervescent', 'eg', 'egg', 'eggs', 'egyptian', 'ehe', 'eight', 'el', 'elbows', 'elderberries', 'elderflower', 'electric', 'electrolyte', 'electrolytes', 'elegant', 'elements', 'elephant', 'elevate', 'eliminates', 'elk', 'email', 'embassy', 'emergen', 'emergency', 'emery', 'emissions', 'emoji', 'employees', 'empowers', 'empty', 'end', 'energizer', 'energy', 'english', 'enjoy', 'enjoying', 'enriched', 'ensure', 'ensures', 'enticing', 'entree', 'entries', 'envelope', 'enveloped', 'envelopes', 'envipods', 'environmental', 'enzyme', 'enzymes', 'epic', 'epis', 'equal', 'equivalent', 'er', 'erin', 'erlanger', 'ers', 'erykah', 'erythritol', 'espressione', 'espresso', 'espressos', 'esquire', 'essential', 'essentials', 'estates', 'ethiopia', 'ethyl', 'eucalyptus', 'european', 'even', 'evening', 'evergreen', 'everlasting', 'everthing', 'every', 'everyday', 'everything', 'ex', 'excel', 'excellence', 'excellent', 'exciting', 'exclusive', 'exhibits', 'exotic', 'expedition', 'experience', 'experiment', 'expertly', 'expiration', 'expires', 'explore', 'explosive', 'exposures', 'express', 'expressions', 'exquisite', 'ext', 'exterior', 'extra', 'extract', 'extracted', 'extreme', 'eye', 'f', 'fabulous', 'face', 'facebook', 'facial', 'facilities', 'factors', 'factory', 'fahrenheit', 'fairytale', 'fajitas', 'false', 'families', 'family', 'famous', 'fan', 'fannie', 'fans', 'fanta', 'fantastic', 'fantasy', 'farm', 'farmer', 'farmers', 'farming', 'farms', 'fast', 'fasteners', 'fat', 'fats', 'fatty', 'faux', 'favor', 'favorite', 'favoritenaturally', 'favorites', 'favours', 'fax', 'fcc', 'fdc', 'fdsvc', 'feast', 'featured', 'features', 'featuring', 'federal', 'fedora', 'fee', 'feed', 'feeding', 'feeling', 'feet', 'felitsa', 'felix', 'felt', 'female', 'fenugreek', 'fermentation', 'fermentis', 'ferrara', 'fertilizer', 'festival', 'festive', 'fettuccine', 'fewer', 'fg', 'fi', 'fiber', 'fibrous', 'fiddle', 'fiery', 'fiesta', 'fifteen', 'fig', 'fights', 'figs', 'fill', 'filled', 'filler', 'fillers', 'filling', 'film', 'filter', 'filterbags', 'filters', 'fin', 'final', 'finale', 'find', 'fine', 'finest', 'finger', 'finishes', 'firehouse', 'fireside', 'first', 'fish', 'fit', 'fits', 'fitsip', 'fitted', 'fittest', 'fitting', 'five', 'fivstr', 'fix', 'fixation', 'fl', 'flag', 'flagship', 'flaky', 'flame', 'flames', 'flamin', 'flamingle', 'flapjacked', 'flapjacks', 'flashin', 'flat', 'flatbreads', 'flattering', 'flavacol', 'flavor', 'flavored', 'flavores', 'flavorful', 'flavoring', 'flavors', 'flavour', 'flavoured', 'flavourful', 'flavours', 'flax', 'fleece', 'flesh', 'flexible', 'flight', 'flip', 'floating', 'flood', 'floor', 'flour', 'flower', 'flowers', 'floz', 'flu', 'fluff', 'fluffy', 'fluid', 'fluif', 'flushable', 'flushed', 'flux', 'flv', 'flvr', 'flying', 'fo', 'foam', 'focus', 'foil', 'foils', 'fold', 'folders', 'folgers', 'followers', 'following', 'fondant', 'fonio', 'food', 'foods', 'foot', 'football', 'for', 'forbidden', 'foreign', 'forest', 'forks', 'form', 'format', 'formula', 'forte', 'fortified', 'fortune', 'foundation', 'founded', 'four', 'fourth', 'fox', 'fp', 'fr', 'frac', 'fraction', 'fragrances', 'fragrant', 'frankencakes', 'frankincense', 'franz', 'free', 'freebie', 'freeze', 'freezer', 'french', 'fresh', 'freshly', 'freshness', 'fridge', 'friendly', 'friends', 'fries', 'fright', 'frito', 'fritos', 'fritters', 'frogs', 'from', 'froot', 'frooties', 'frosted', 'frosting', 'frozen', 'fruit', 'fruits', 'fruity', 'fruttato', 'fry', 'ft', 'fudge', 'fuel', 'fuji', 'full', 'fullerene', 'fully', 'fulvic', 'fun', 'function', 'functional', 'fund', 'funfetti', 'funnel', 'funnels', 'funny', 'funsia', 'funyuns', 'further', 'fusilli', 'future', 'futuro', 'fuzzy', 'fz', 'fzcountry', 'fzpack', 'g', 'ga', 'gal', 'galactic', 'galettes', 'galletas', 'galllon', 'galllons', 'gallon', 'gallons', 'galloon', 'galon', 'gals', 'game', 'gamma', 'ganmao', 'gar', 'garbanzo', 'garden', 'gardens', 'garland', 'garlic', 'garnish', 'gastroenterologist', 'gatorade', 'gaudum', 'gauge', 'gb', 'gbottle', 'gcalorific', 'gcholesterol', 'gea', 'gecko', 'gefilte', 'gel', 'gelatin', 'gelcaps', 'gelpacs', 'gels', 'gelt', 'gems', 'generated', 'generation', 'generations', 'generous', 'generously', 'genre', 'gentle', 'gently', 'genuine', 'gerbera', 'gerberas', 'german', 'get', 'gevalia', 'geyser', 'gf', 'ghee', 'gherkins', 'ghirardelli', 'gi', 'giant', 'gift', 'giftable', 'gifts', 'gillette', 'ginger', 'gingerbread', 'gingers', 'gir', 'giuliano', 'giuseppe', 'giustos', 'give', 'gives', 'giving', 'gk', 'gkeurigcelestial', 'gkinder', 'gl', 'gla', 'glaceau', 'glacer', 'glacier', 'glamour', 'glass', 'glasses', 'glaze', 'glazed', 'gliders', 'glittering', 'glittery', 'glmjtl', 'global', 'globally', 'glucose', 'glueten', 'gluta', 'gluten', 'glycemic', 'gm', 'gms', 'gn', 'gnc', 'go', 'goal', 'goals', 'goat', 'goats', 'gobinday', 'gochujang', 'gogo', 'gold', 'golden', 'goldfish', 'golly', 'good', 'goodie', 'googly', 'gorgeous', 'gosip', 'gosutoys', 'gouda', 'gourmet', 'gpb', 'gprotein', 'gr', 'gra', 'grab', 'grade', 'gradually', 'graduation', 'graham', 'grahams', 'grain', 'grains', 'gram', 'gramof', 'gramos', 'grams', 'gramsalmondina', 'gramtotal', 'gran', 'grand', 'grandes', 'granny', 'granola', 'granulated', 'grape', 'grapefruit', 'grapes', 'graphic', 'grass', 'grassfed', 'gravy', 'gray', 'grease', 'great', 'greater', 'greatest', 'green', 'greens', 'grevilia', 'griddle', 'grill', 'grilled', 'grilling', 'grillo', 'grind', 'gringo', 'gringos', 'grip', 'grit', 'grm', 'grn', 'grocery', 'groom', 'ground', 'grounded', 'grow', 'grower', 'growers', 'growing', 'grown', 'grq', 'grs', 'gs', 'gstevia', 'gtf', 'gtrans', 'guarana', 'guarantee', 'guaranteed', 'guarantees', 'guard', 'guatemalan', 'guava', 'guayusa', 'guessing', 'guests', 'guidelines', 'guilt', 'gulps', 'gum', 'gumball', 'gumballs', 'gummi', 'gummies', 'gummy', 'gumpaste', 'gums', 'guntar', 'gvchpin', 'gvitamin', 'gwhole', 'gx', 'h', 'habanero', 'habanerofire', 'habaneros', 'haccp', 'had', 'hails', 'hain', 'hair', 'halal', 'halb', 'haldi', 'half', 'halloween', 'halls', 'halva', 'halvah', 'hamantaschen', 'hamburger', 'hamen', 'hamentaschen', 'hamentashen', 'hampton', 'hand', 'handcrafted', 'handfuls', 'handi', 'handle', 'handmade', 'handpicked', 'hands', 'hang', 'hanging', 'hanukkah', 'hapi', 'happiness', 'happy', 'hard', 'haribo', 'harissa', 'harmful', 'harney', 'harvest', 'has', 'hatch', 'hats', 'have', 'hawaiian', 'hazelnut', 'hazelnuts', 'hb', 'hd', 'hdpe', 'he', 'head', 'heads', 'health', 'healthcare', 'healthier', 'healthy', 'healthybalance', 'heap', 'heaped', 'heaping', 'hearing', 'heart', 'hearth', 'hearts', 'heartwarming', 'hearty', 'heat', 'heavenly', 'heavy', 'hectare', 'hectares', 'heel', 'hefty', 'height', 'heinz', 'heirloom', 'hel', 'heliconia', 'hello', 'help', 'helps', 'hemp', 'henna', 'henrietta', 'her', 'herb', 'herbal', 'herbs', 'hermit', 'hero', 'hershey', 'herstellte', 'hfss', 'hi', 'hibiscus', 'high', 'higher', 'highlander', 'highly', 'hilarious', 'hills', 'himalayan', 'himself', 'his', 'historical', 'hives', 'hnrps', 'hoagie', 'hog', 'hohos', 'hold', 'holders', 'hole', 'holes', 'holiday', 'hollow', 'holy', 'home', 'homemade', 'homestyle', 'honduran', 'honey', 'honeystix', 'honoring', 'hook', 'hooks', 'horizon', 'hormel', 'horse', 'hostess', 'hostesscakes', 'hot', 'hotdogs', 'hottest', 'hour', 'hours', 'house', 'houses', 'how', 'however', 'hp', 'hr', 'hrs', 'hrt', 'hrvst', 'hs', 'hsmyvbq', 'hu', 'huckleberry', 'huge', 'huggies', 'human', 'hungry', 'hush', 'huthis', 'hydrangea', 'hydrant', 'hydrate', 'hydrates', 'hydrating', 'hydration', 'hydrogenated', 'hypoallergenic', 'hz', 'i', 'iasm', 'ibc', 'ibew', 'ibs', 'ibu', 'ibuprofen', 'ibus', 'ice', 'iced', 'icing', 'iconic', 'icy', 'ideal', 'ideally', 'ideas', 'identical', 'identifiable', 'if', 'iinches', 'ilb', 'iliters', 'illy', 'imcu', 'immediately', 'immune', 'immunity', 'imp', 'imperfect', 'imperial', 'important', 'imported', 'impression', 'improved', 'improves', 'impurities', 'imxi', 'in', 'inch', 'inches', 'inchescubic', 'inchesgtin', 'inchesheight', 'inchesitem', 'inchesl', 'inchespackage', 'incheswidth', 'inchs', 'included', 'includes', 'increased', 'increases', 'incredible', 'independent', 'independents', 'index', 'indicates', 'indigenous', 'indiv', 'individaully', 'individual', 'individually', 'individuals', 'individualy', 'indivividually', 'indoor', 'indulge', 'indulgent', 'industry', 'induvidual', 'indvidually', 'infant', 'info', 'infused', 'infuser', 'infusers', 'infuses', 'infusi', 'infusion', 'infusions', 'infusori', 'ingrediants', 'ingredient', 'ingredientegg', 'ingredientes', 'ingredients', 'ingredientspotato', 'ingredientsunbleached', 'inh', 'inhinches', 'inhx', 'initially', 'inject', 'ink', 'inl', 'inmade', 'inner', 'innovative', 'inside', 'inspect', 'inspired', 'instagram', 'installing', 'instant', 'instantized', 'instantly', 'instead', 'instruction', 'instructions', 'insulated', 'intelligentsia', 'intense', 'intensely', 'intensity', 'intensive', 'intenso', 'intermediate', 'international', 'internationally', 'intl', 'into', 'introducing', 'introduction', 'inventions', 'inverted', 'investing', 'invidually', 'invigorating', 'invisible', 'inviting', 'inw', 'ionic', 'ionized', 'ions', 'iperespresso', 'iqjoe', 'iqvia', 'irish', 'iroc', 'irresistible', 'irresistibly', 'irresitable', 'is', 'island', 'islands', 'islnd', 'isolate', 'isoparaffin', 'israeli', 'issue', 'it', 'italian', 'item', 'items', 'its', 'iu', 'ius', 'ivoire', 'ivory', 'j', 'jabez', 'jack', 'jacks', 'jade', 'jahren', 'jala', 'jalapeno', 'jalfrezi', 'jamaican', 'james', 'japanese', 'jar', 'jarritos', 'jars', 'jasmine', 'jason', 'java', 'jawline', 'jellies', 'jelly', 'jerky', 'jesus', 'jewel', 'jewish', 'jimoco', 'jn', 'job', 'joe', 'john', 'johnny', 'join', 'joist', 'jolly', 'jordan', 'joshua', 'jours', 'jovy', 'joyful', 'jpg', 'jsk', 'judaica', 'jufran', 'jug', 'jugs', 'juice', 'juices', 'juicy', 'jules', 'jumbo', 'junket', 'just', 'k', 'kacip', 'kaffeekapseln', 'kansas', 'karachi', 'karat', 'karo', 'kashi', 'kava', 'kawaii', 'kbp', 'kcal', 'kcup', 'kcups', 'kedem', 'keebler', 'keemun', 'keep', 'keeps', 'kellogg', 'ken', 'kentucky', 'kernel', 'kernels', 'ketchup', 'keto', 'kettle', 'keurig', 'key', 'keys', 'kg', 'kgs', 'kickass', 'kid', 'kids', 'kidsmania', 'kies', 'kilo', 'kilobag', 'kilocalories', 'kilogram', 'kilograms', 'kilojoules', 'kilometer', 'kilometers', 'kilos', 'kimchi', 'kind', 'kinder', 'kinds', 'king', 'kingredients', 'kinnikritters', 'kirkland', 'kisser', 'kisses', 'kit', 'kitchen', 'kitchens', 'kits', 'kitty', 'kiwi', 'kj', 'kleenex', 'km', 'knead', 'knock', 'knorr', 'known', 'koh', 'kombucha', 'kona', 'kool', 'korean', 'kosher', 'kosmos', 'kp', 'kpack', 'krabby', 'kraft', 'krusteaz', 'ktis', 'kukicha', 'kula', 'kw', 'kwh', 'l', 'la', 'lab', 'label', 'labeled', 'labels', 'lace', 'laces', 'lactation', 'lady', 'lake', 'lala', 'lalvin', 'lamor', 'land', 'lanyards', 'lapsang', 'laradeo', 'large', 'larger', 'largo', 'las', 'lasagna', 'lashes', 'last', 'latas', 'late', 'latte', 'lattes', 'laundry', 'lauric', 'lavash', 'lavazza', 'lavender', 'lawn', 'lawry', 'laxative', 'laxattive', 'lay', 'layer', 'layered', 'layers', 'lb', 'lbassorted', 'lbbubble', 'lbbulk', 'lbcafe', 'lbpack', 'lbs', 'lbsupc', 'le', 'leader', 'leading', 'leaf', 'leak', 'lean', 'learn', 'leas', 'leather', 'leave', 'leaves', 'led', 'leed', 'legacy', 'legume', 'leland', 'lemon', 'lemonade', 'lemons', 'length', 'lentil', 'lentils', 'less', 'let', 'lets', 'letter', 'lettuce', 'level', 'levels', 'lg', 'lgbtq', 'lght', 'libras', 'lick', 'licorice', 'lid', 'lidestri', 'lids', 'lieber', 'liege', 'life', 'lifesip', 'lifetimes', 'lift', 'light', 'lightly', 'lightweight', 'like', 'lilies', 'lillie', 'lilly', 'lime', 'limes', 'limit', 'limited', 'limon', 'lindor', 'lindt', 'liners', 'lines', 'lineup', 'linguine', 'link', 'links', 'linoleic', 'linolenic', 'lint', 'linzer', 'lion', 'lip', 'liposomal', 'lipton', 'liquicaps', 'liquid', 'liquidplumr', 'list', 'lite', 'liter', 'liters', 'lithium', 'litre', 'litres', 'litros', 'litter', 'little', 'live', 'lives', 'living', 'llb', 'llbs', 'llc', 'lly', 'load', 'loaded', 'loads', 'loaf', 'loafs', 'loaves', 'local', 'locals', 'located', 'locations', 'lodge', 'lolasfinehotsauce', 'lolli', 'lollies', 'lollipop', 'lollipops', 'london', 'long', 'longwear', 'look', 'lookalike', 'looking', 'loose', 'lord', 'los', 'losing', 'lotion', 'love', 'lovely', 'lovibond', 'low', 'lower', 'loz', 'lozenge', 'lozenges', 'lt', 'ltr', 'ltrs', 'lucas', 'lucky', 'lumens', 'luminous', 'luna', 'lunch', 'lunches', 'lungo', 'lure', 'luscious', 'lush', 'lustrous', 'lux', 'luxe', 'luxurious', 'luxuriously', 'lx', 'lychee', 'm', 'ma', 'mac', 'macadamia', 'macaroni', 'macaroons', 'machine', 'machines', 'macros', 'madagascar', 'maddys', 'made', 'madhava', 'maffles', 'mag', 'magazine', 'maggi', 'magic', 'magnetic', 'magnificent', 'mah', 'maher', 'mai', 'mail', 'main', 'maison', 'major', 'majority', 'make', 'makes', 'malbec', 'male', 'malt', 'malta', 'mama', 'mancini', 'mandarins', 'mango', 'manicures', 'manita', 'mantara', 'mantra', 'manufactured', 'manufacturer', 'manufacturers', 'manuka', 'many', 'maple', 'marasca', 'marble', 'marching', 'marco', 'mares', 'margarita', 'margherite', 'marginata', 'mariani', 'marinate', 'markers', 'marketability', 'markets', 'marley', 'maroma', 'marshmallow', 'marshmallows', 'martinelli', 'martinson', 'mary', 'masajeana', 'masala', 'maseca', 'mashed', 'mashes', 'masl', 'master', 'matador', 'matcha', 'matching', 'matchsticks', 'mate', 'materials', 'mato', 'matzo', 'maui', 'max', 'maximum', 'maximun', 'maxwell', 'may', 'mayan', 'mayo', 'mayonnaise', 'mazapan', 'mb', 'mcallister', 'mccafe', 'mccormick', 'mcg', 'mckee', 'mct', 'mcts', 'me', 'meadow', 'meal', 'meals', 'mean', 'means', 'meant', 'measures', 'measuring', 'meat', 'meats', 'meaty', 'mechanical', 'med', 'medaglie', 'medals', 'medical', 'medications', 'medicinal', 'mediterranean', 'medium', 'medley', 'mega', 'meijer', 'melamine', 'melatonin', 'melissaanddoug', 'melitta', 'melon', 'melozio', 'melt', 'member', 'members', 'memorabilia', 'memorable', 'memory', 'memphis', 'men', 'menorah', 'mens', 'menthol', 'mentos', 'menus', 'meq', 'meqo', 'meringue', 'mermaid', 'merritt', 'merry', 'meses', 'mesh', 'mess', 'metal', 'metallic', 'meter', 'metered', 'meters', 'method', 'meticulously', 'metres', 'metric', 'mex', 'mexican', 'mexico', 'meyer', 'mezzetta', 'mf', 'mfrs', 'mg', 'mgkg', 'mgof', 'mgs', 'mhz', 'mi', 'miapply', 'michael', 'michelin', 'michigan', 'microdrink', 'microgreen', 'micron', 'microns', 'micronutrients', 'microplastic', 'microwavable', 'microwave', 'microwaveable', 'mid', 'midnight', 'mighty', 'miir', 'mike', 'mil', 'milano', 'mild', 'mildly', 'mile', 'miles', 'mililiters', 'milk', 'milka', 'milked', 'milkshake', 'milli', 'millig', 'milligram', 'milligrams', 'milliliter', 'milliliters', 'millilitre', 'millimeter', 'millimeters', 'millimetres', 'million', 'millions', 'mills', 'mimosas', 'min', 'minced', 'mineral', 'minerals', 'mini', 'miniature', 'minijumbo', 'minimuffins', 'minimun', 'minis', 'mins', 'mint', 'mints', 'mintues', 'minu', 'minute', 'minuted', 'minuterice', 'minutes', 'minutespositively', 'minutos', 'mio', 'miracle', 'mis', 'miscela', 'miso', 'miss', 'mists', 'mix', 'mixed', 'mixes', 'ml', 'mlpack', 'mls', 'mm', 'mmgumball', 'mmgumballs', 'mmhg', 'mmol', 'mo', 'mocha', 'mochi', 'mocktails', 'model', 'models', 'moderately', 'modern', 'moderna', 'modes', 'mogroside', 'mohawk', 'moist', 'moisten', 'moisture', 'moisturizers', 'moisturizing', 'mojito', 'molasses', 'molds', 'molina', 'molokai', 'mom', 'mon', 'monday', 'monin', 'monitor', 'monk', 'monkeys', 'monounsaturated', 'monstera', 'month', 'months', 'monthscertified', 'mood', 'moonlit', 'mopping', 'more', 'morel', 'moreover', 'moringa', 'moroccan', 'morocn', 'mos', 'mosquito', 'most', 'mother', 'mott', 'motts', 'mounds', 'mountain', 'mountains', 'mounting', 'mouth', 'mouthwatering', 'move', 'movie', 'moxie', 'mozart', 'mph', 'mr', 'mre', 'mrs', 'mrsrenfros', 'ms', 'msg', 'mt', 'mths', 'mtolivepickles', 'muddler', 'muddy', 'muffin', 'muffins', 'mugs', 'mugwort', 'mular', 'mullein', 'multi', 'multicolored', 'multifunction', 'multigrain', 'multiple', 'munchies', 'mung', 'mus', 'musa', 'muscle', 'mushroom', 'mushrooms', 'musketeer', 'musketeers', 'muslin', 'must', 'mustard', 'mw', 'mx', 'my', 'mykos', 'myles', 'myntz', 'myojo', 'mystery', 'n', 'nabisco', 'nacho', 'nails', 'naked', 'nantucket', 'naoh', 'napa', 'napkins', 'napoleon', 'nasft', 'nashville', 'national', 'natural', 'naturally', 'naturals', 'nature', 'naturejam', 'naughty', 'nautral', 'navel', 'nb', 'nc', 'ncaa', 'nd', 'ndc', 'ndividually', 'ne', 'neck', 'necklaces', 'nectar', 'needle', 'needs', 'neighborhood', 'nelle', 'neon', 'nesco', 'nespresso', 'nestle', 'nests', 'net', 'netflix', 'nettle', 'neuhaus', 'neutral', 'never', 'new', 'newly', 'newman', 'news', 'newspaper', 'newtons', 'next', 'nexty', 'nice', 'nickelodeon', 'nielseniq', 'nigella', 'nightbird', 'nightly', 'nights', 'nighttime', 'nimh', 'ninechef', 'nintendo', 'nissin', 'nl', 'nm', 'nmqlbkz', 'no', 'nocco', 'nola', 'non', 'nondairy', 'none', 'nonni', 'nonstick', 'noodle', 'noodles', 'nori', 'northeast', 'nose', 'nostalgia', 'not', 'note', 'notes', 'nothing', 'notice', 'nottingham', 'nourishing', 'novel', 'novelties', 'novelty', 'now', 'nozzles', 'nrombox', 'ntrl', 'nude', 'number', 'numbers', 'numeral', 'numi', 'nurse', 'nut', 'nutirition', 'nutiva', 'nutri', 'nutrient', 'nutrients', 'nutrievo', 'nutritents', 'nutrition', 'nutritional', 'nutritious', 'nutritn', 'nuts', 'nutsie', 'nutter', 'nv', 'ny', 'nyiooc', 'nz', 'o', 'oat', 'oatmeal', 'ob', 'oc', 'occasions', 'ocean', 'odacio', 'odor', 'odorshield', 'of', 'off', 'offers', 'official', 'og', 'ohmarket', 'ohms', 'oil', 'oils', 'old', 'olive', 'oliveoil', 'olives', 'omaha', 'omega', 'omegas', 'omori', 'on', 'once', 'onces', 'one', 'onequart', 'onion', 'only', 'onuce', 'onwards', 'onz', 'onzas', 'oof', 'oolong', 'ooml', 'oounce', 'opaque', 'ope', 'open', 'opening', 'oppenheim', 'ops', 'optic', 'options', 'or', 'orac', 'oran', 'orang', 'orange', 'oranges', 'orbit', 'orchard', 'orchid', 'order', 'oregano', 'oregon', 'oreo', 'oreos', 'org', 'organic', 'organically', 'organics', 'organza', 'orgvl', 'oriental', 'origin', 'original', 'origins', 'ornaments', 'orp', 'ortega', 'orzo', 'os', 'osulloc', 'other', 'otis', 'ouce', 'oun', 'ounc', 'ounca', 'ounce', 'ouncee', 'ounceresealable', 'ounces', 'ounceseasoning', 'ouncesenjoy', 'oune', 'ount', 'our', 'out', 'outlet', 'outside', 'oval', 'oven', 'over', 'overall', 'overload', 'overnight', 'oversized', 'ox', 'oxalates', 'oxygen', 'oyster', 'oz', 'ozcathairballcontrol', 'ozcoffee', 'ozcountry', 'ozf', 'ozfeaturesuse', 'ozflower', 'ozingredients', 'ozingredientshoisin', 'ozis', 'ozklnders', 'oznature', 'ozpack', 'ozproduct', 'ozs', 'ozservings', 'ozspecifications', 'ozunce', 'p', 'pacifiers', 'pack', 'package', 'packaged', 'packager', 'packages', 'packaging', 'packcanned', 'packed', 'packet', 'packets', 'packetsindividually', 'packges', 'packing', 'packk', 'packmentos', 'packof', 'packs', 'pacs', 'pads', 'paediatrician', 'page', 'pages', 'pail', 'paillettes', 'paint', 'painted', 'pair', 'pairs', 'pak', 'pakcs', 'paleo', 'palettes', 'pallet', 'pallets', 'palms', 'pamelas', 'pamper', 'pan', 'pancake', 'pancakes', 'panda', 'pandanus', 'pandemic', 'paneer', 'panels', 'panettone', 'pango', 'panko', 'pantry', 'papadums', 'papas', 'paper', 'pappardelle', 'paprika', 'paquetes', 'paqueticos', 'para', 'paradise', 'parents', 'parfait', 'paris', 'parm', 'parmesan', 'parrot', 'parsley', 'part', 'parties', 'partnering', 'parts', 'party', 'parvipholia', 'passed', 'passion', 'pasta', 'paste', 'pastel', 'pastene', 'pastille', 'pastilles', 'pastor', 'pastries', 'pastry', 'patak', 'pataks', 'patches', 'paths', 'patriotic', 'patriots', 'patties', 'paul', 'paw', 'pb', 'pc', 'pces', 'pck', 'pckges', 'pckts', 'pcpack', 'pcs', 'pct', 'peace', 'peach', 'peaches', 'peanut', 'peanuts', 'pear', 'pearilized', 'pearl', 'pears', 'peas', 'pecan', 'peck', 'pectin', 'pedialyte', 'pediatrician', 'pediatricians', 'peel', 'peeled', 'peeps', 'peer', 'peet', 'peg', 'peices', 'pellet', 'pelletlactose', 'pelletproduct', 'pellets', 'pelon', 'peloneta', 'pen', 'pencils', 'penne', 'pennsylvania', 'peony', 'people', 'peoples', 'pepper', 'peppercorn', 'peppercorns', 'peppered', 'pepperidge', 'peppermint', 'peppermints', 'pepperoni', 'peppers', 'pepsi', 'per', 'percent', 'percentage', 'perdue', 'perfect', 'perfectly', 'performance', 'period', 'permanent', 'perrier', 'person', 'personal', 'personalized', 'persons', 'peruvian', 'pesticides', 'pet', 'petal', 'petals', 'petite', 'petits', 'petri', 'pez', 'pg', 'ph', 'pharmacist', 'philadelphia', 'photo', 'photos', 'phyllo', 'pica', 'picarones', 'pices', 'picked', 'pickle', 'pickled', 'pickles', 'pickling', 'picks', 'picture', 'pie', 'piece', 'piececount', 'pieces', 'piecespecifications', 'piect', 'pier', 'pierogies', 'pierogis', 'pies', 'piezas', 'pikitikis', 'pill', 'pillars', 'pillow', 'pills', 'pina', 'pinch', 'pinches', 'pine', 'pineapple', 'pink', 'pint', 'pinta', 'pints', 'pioneer', 'piping', 'pirouline', 'pistachio', 'pit', 'pita', 'pitas', 'pitcher', 'pitchers', 'pitted', 'pittosporum', 'pizza', 'pizzas', 'pizzeria', 'pj', 'pk', 'pkg', 'pkgs', 'pks', 'pkt', 'pkts', 'pl', 'place', 'places', 'plague', 'plaid', 'plain', 'planet', 'plant', 'plantago', 'plantain', 'planter', 'planters', 'planting', 'plants', 'plastic', 'plastics', 'plastik', 'plates', 'platinum', 'play', 'players', 'plays', 'please', 'plts', 'plucking', 'plumosus', 'plus', 'plusfruit', 'plush', 'plussparkling', 'ply', 'pm', 'png', 'po', 'pocket', 'pockets', 'pod', 'poderosos', 'pods', 'point', 'points', 'pointsplus', 'poker', 'polarbeverages', 'polished', 'pollutants', 'polypro', 'polypropylene', 'polystyrene', 'polyunsaturated', 'pom', 'pomegranate', 'pony', 'pool', 'pop', 'popchips', 'popcifier', 'popcorn', 'popcorners', 'popovers', 'popping', 'poppy', 'pops', 'popsicles', 'popular', 'porcelain', 'porciones', 'pork', 'portable', 'porters', 'portfolio', 'portico', 'portion', 'portionen', 'portions', 'portland', 'portside', 'post', 'pot', 'potato', 'potatoes', 'potent', 'potential', 'potentially', 'pothos', 'pots', 'pouch', 'pouches', 'pouchesper', 'pouchserving', 'pounc', 'pounces', 'pound', 'pounde', 'pounds', 'poundsdescriptionsmoky', 'poundsdescriptionthe', 'poundslength', 'poundspackage', 'poundsweet', 'pour', 'pouring', 'powder', 'powdered', 'power', 'powered', 'powerful', 'powerhouse', 'pp', 'ppm', 'pr', 'practicing', 'pralines', 'prayer', 'prcnt', 'pre', 'precious', 'precision', 'precut', 'predium', 'preferred', 'prefilled', 'preformed', 'pregnancy', 'preheat', 'prem', 'premeasured', 'premier', 'premium', 'premiun', 'premix', 'premum', 'prep', 'prepare', 'prepared', 'preprinted', 'present', 'presentations', 'presents', 'preservative', 'preservatives', 'press', 'pressed', 'pressure', 'prestigious', 'pretied', 'pretzel', 'pretzels', 'previously', 'prides', 'primary', 'prime', 'principles', 'pringles', 'printers', 'priority', 'prism', 'pro', 'proactive', 'probiotic', 'probiotics', 'procent', 'process', 'processes', 'produced', 'producer', 'producers', 'product', 'production', 'productos', 'products', 'professional', 'proglide', 'programs', 'promises', 'promote', 'promotes', 'proof', 'propel', 'proportion', 'proportions', 'prospect', 'protected', 'protection', 'protein', 'proteins', 'proudly', 'proven', 'provide', 'provides', 'proving', 'prred', 'prremimum', 'prunes', 'ps', 'psc', 'psi', 'psl', 'pt', 'ptb', 'ptd', 'ptp', 'pts', 'pu', 'pub', 'published', 'pucks', 'pudding', 'puddings', 'puerto', 'puffed', 'puffins', 'puffs', 'pulgadas', 'pull', 'pulparindo', 'pulparindots', 'pulses', 'pump', 'pumpkin', 'pumpkins', 'pumps', 'puna', 'punalu', 'punch', 'puncture', 'purchase', 'pure', 'puree', 'pureed', 'purees', 'purified', 'purity', 'purple', 'purpose', 'push', 'put', 'pwdrd', 'pww', 'px', 'pyramid', 'pyramids', 'pz', 'qq', 'qt', 'qts', 'qty', 'quaker', 'quality', 'quantity', 'quart', 'quarter', 'quarters', 'quarts', 'queen', 'questions', 'quick', 'quills', 'quilogramas', 'quilted', 'quinoa', 'quntil', 'quot', 'qwik', 'r', 'rack', 'radiatore', 'rafines', 'rail', 'rain', 'rainbow', 'ramen', 'ran', 'ranch', 'rani', 'raphis', 'rapidfire', 'rapitest', 'rare', 'rareessence', 'raseley', 'raspberry', 'rated', 'rating', 'ratio', 'rattlesnake', 'rava', 'ravioli', 'raw', 'razor', 'razors', 'rd', 'rdi', 'rds', 're', 'rea', 'reached', 'read', 'ready', 'real', 'really', 'ream', 'reaper', 'reaseable', 'reason', 'reasons', 'recently', 'recharge', 'recipe', 'recipes', 'reclosable', 'recloseable', 'recommended', 'recovery', 'rectangle', 'rectangular', 'recyclable', 'recycle', 'red', 'redbox', 'reduce', 'reduced', 'reeds', 'reese', 'refer', 'references', 'refill', 'refillable', 'refills', 'refined', 'reflective', 'refractive', 'refresh', 'refreshing', 'refrigerate', 'reg', 'regarding', 'regata', 'regional', 'registered', 'regrets', 'regrind', 'regular', 'reimbursable', 'reinforced', 'reishi', 'relaunched', 'relaxed', 'relaxing', 'released', 'relish', 'rellerindos', 'reload', 'remaster', 'remedies', 'removable', 'remove', 'renal', 'rennet', 'renowned', 'renwood', 'repair', 'replace', 'replacement', 'report', 'represents', 'reptile', 'required', 'requirement', 'requirements', 'reseal', 'resealable', 'resealble', 'research', 'reserve', 'reset', 'residents', 'respectively', 'responsible', 'restaurants', 'restoring', 'resulting', 'results', 'retail', 'retinol', 'retractable', 'reusable', 'reynolds', 'rhubarb', 'rib', 'riboflavin', 'rice', 'rich', 'richly', 'ridiculously', 'rifle', 'riga', 'rigatoni', 'rigorous', 'rimming', 'ring', 'rings', 'rinse', 'ripe', 'ristretto', 'ritos', 'ritz', 'rivers', 'rj', 'rl', 'roast', 'roasted', 'roasting', 'robust', 'rocher', 'rockaleta', 'rocket', 'rodeo', 'roland', 'rold', 'roll', 'rollers', 'rolling', 'rolls', 'roma', 'rooibos', 'root', 'rootbeer', 'rooted', 'roots', 'rope', 'ropes', 'rose', 'rosebud', 'rosehip', 'rosemary', 'roses', 'rosso', 'rotating', 'rotation', 'round', 'rounded', 'rounds', 'routin', 'row', 'rows', 'royal', 'rsmokehouse', 'rub', 'ruby', 'ruffles', 'rugelach', 'rugelech', 'rule', 'ruled', 'rules', 'rum', 'run', 'runner', 'running', 'ruscus', 'ruth', 'rx', 'rxbar', 'rxbars', 's', 'sa', 'saccharin', 'saccharomyces', 'sacchetto', 'sachet', 'sachets', 'sackets', 'saddle', 'sae', 'saf', 'safety', 'sage', 'sahale', 'sahara', 'sahlen', 'salad', 'salero', 'sales', 'salon', 'salsa', 'salsaguetti', 'salsas', 'salt', 'salted', 'salts', 'salty', 'salute', 'salvatore', 'same', 'sample', 'sampler', 'samplers', 'samples', 'samy', 'san', 'sanderiana', 'sanding', 'sandwich', 'sandwiches', 'sansiveria', 'santiago', 'santo', 'santorini', 'sapphire', 'sardines', 'sat', 'satellite', 'satin', 'satisfaction', 'satisfied', 'satisfy', 'satisfying', 'saturated', 'sauce', 'saucers', 'sauces', 'sauer', 'sausage', 'save', 'savers', 'savor', 'savory', 'saw', 'says', 'scale', 'scalloped', 'scatter', 'scent', 'scented', 'schluender', 'schools', 'schweppesus', 'science', 'scientific', 'scientifically', 'scones', 'scooby', 'scoop', 'scoops', 'scor', 'score', 'scorpion', 'scotland', 'scottish', 'scovie', 'scoville', 'scovilles', 'scratch', 'screen', 'screw', 'screws', 'scripture', 'scrub', 'scrubbers', 'scrumptious', 'scuro', 'sdaother', 'se', 'sea', 'seafood', 'seal', 'sealed', 'seals', 'sealsthis', 'sears', 'seas', 'seashell', 'season', 'seasonal', 'seasonally', 'seasoned', 'seasoning', 'seasonings', 'seasons', 'seattle', 'sec', 'second', 'seconds', 'secondsevery', 'secret', 'secs', 'section', 'sectional', 'sections', 'secure', 'sedentary', 'seduction', 'seed', 'seeds', 'seeking', 'segments', 'segundos', 'seine', 'select', 'self', 'seller', 'sellers', 'selling', 'seltzer', 'seltzers', 'semi', 'sencha', 'send', 'senseo', 'sensible', 'sensitivity', 'separate', 'separately', 'seperate', 'seperately', 'serenity', 'series', 'serv', 'serve', 'serves', 'servimgs', 'serving', 'servings', 'servingsformulated', 'servingskosher', 'servingsnet', 'servingsserving', 'sesame', 'set', 'setchef', 'sets', 'setting', 'settings', 'seven', 'seventh', 'sf', 'sft', 'sg', 'sgwt', 'shades', 'shady', 'shake', 'shaker', 'shakes', 'shampoo', 'shampoos', 'shan', 'shape', 'shaped', 'shapes', 'sharable', 'share', 'shareable', 'sharing', 'shark', 'sharks', 'sharpeners', 'shasta', 'shaved', 'shaver', 'she', 'sheet', 'sheets', 'shelf', 'shelled', 'shells', 'shine', 'ship', 'shit', 'shoots', 'shop', 'short', 'shortbread', 'shortcake', 'shot', 'shots', 'shred', 'shrimp', 'shrink', 'sht', 'shu', 'shus', 'shutout', 'siberian', 'side', 'sided', 'sides', 'sign', 'signable', 'signature', 'signs', 'silicone', 'silk', 'silky', 'silly', 'silver', 'silverado', 'simmer', 'simmering', 'simple', 'simpler', 'simplify', 'simply', 'since', 'sinful', 'singapore', 'single', 'singles', 'sisters', 'site', 'six', 'sixes', 'sixlets', 'size', 'sized', 'sizes', 'skeleton', 'skewer', 'skilled', 'skillet', 'skim', 'skin', 'skinless', 'skinny', 'skittle', 'skout', 'skull', 'skyline', 'slab', 'slabs', 'slaps', 'slaw', 'sleek', 'sleeve', 'sleeves', 'slice', 'sliced', 'slices', 'slightly', 'slim', 'slimpaks', 'slow', 'slurpers', 'small', 'smaller', 'smallholder', 'smart', 'smartfood', 'smarties', 'smartlabel', 'smartpoint', 'smiley', 'smith', 'smoke', 'smoked', 'smokey', 'smooth', 'smoothie', 'smucker', 'smuckers', 'snack', 'snackable', 'snacks', 'snakeskin', 'snapple', 'snaps', 'snickerdoodle', 'snickers', 'snoballs', 'snow', 'snowcone', 'snowflake', 'snuggle', 'snyder', 'so', 'soak', 'soaks', 'soap', 'sobres', 'sobresitos', 'sock', 'soda', 'sodium', 'sofa', 'sofi', 'soft', 'softgel', 'softgels', 'solar', 'sold', 'sole', 'solid', 'solomio', 'solomios', 'soluble', 'solution', 'some', 'sonic', 'sons', 'sonsfoods', 'soon', 'soothing', 'sophisticated', 'sorts', 'soundtrack', 'soup', 'soups', 'sour', 'source', 'sources', 'sourcing', 'soursop', 'south', 'southwest', 'southwestern', 'soy', 'soybean', 'soybeans', 'soymilk', 'sp', 'spa', 'spaces', 'spaghetti', 'spaghettini', 'sparkle', 'sparkling', 'sparrows', 'speakers', 'spearmint', 'spears', 'special', 'specially', 'specialty', 'species', 'specific', 'specifically', 'specifications', 'speckling', 'specs', 'spectacular', 'speed', 'speedy', 'spf', 'spice', 'spiced', 'spices', 'spicy', 'spikes', 'spill', 'spinach', 'spine', 'spinner', 'spiral', 'spirits', 'splash', 'split', 'spongebob', 'sponsored', 'spoon', 'spoonfuls', 'spoons', 'sports', 'spot', 'spray', 'sprays', 'spread', 'sprengeri', 'sprigs', 'spring', 'springs', 'sprinkle', 'sprinkled', 'sprinkler', 'sprinkles', 'sprite', 'sprouted', 'sq', 'sqft', 'square', 'squares', 'squeeze', 'squeezed', 'squeezes', 'squeezy', 'squiggle', 'squirrel', 'squirrels', 'squirt', 'squirts', 'sqweeze', 'sqwincher', 'srv', 'ss', 'st', 'stackable', 'stacks', 'stadiums', 'stage', 'stain', 'stainless', 'stainlifter', 'stairs', 'stalk', 'stamp', 'stamped', 'stand', 'standard', 'standards', 'stands', 'staple', 'staples', 'star', 'starbucks', 'starburst', 'starch', 'starchdessert', 'starfish', 'stargazer', 'starlight', 'stars', 'start', 'starter', 'starting', 'stash', 'state', 'states', 'stay', 'steak', 'steakhouse', 'steakhouses', 'steaks', 'stealth', 'steam', 'steamer', 'steel', 'steep', 'steepack', 'steeps', 'stem', 'stems', 'step', 'steps', 'sterile', 'sterling', 'stevia', 'stick', 'sticker', 'stickers', 'stickpack', 'stickpacks', 'sticks', 'stiks', 'still', 'stinging', 'stir', 'stirring', 'stix', 'stk', 'stock', 'stok', 'stone', 'stop', 'storage', 'store', 'stores', 'stories', 'stormio', 'straight', 'strain', 'strainers', 'strains', 'strands', 'straw', 'strawberries', 'strawberry', 'straws', 'street', 'streits', 'strength', 'stretchable', 'string', 'stringless', 'strings', 'strips', 'strong', 'stronger', 'stroopwafels', 'strw', 'stuck', 'studies', 'studs', 'study', 'stuffed', 'stunning', 'sturdy', 'styles', 'subsitute', 'substances', 'substitute', 'substitution', 'subtle', 'such', 'sucker', 'suckers', 'sucralose', 'sugar', 'sugarcane', 'sugars', 'suggested', 'suitable', 'sukhis', 'sum', 'sumatra', 'summer', 'sun', 'sunbutter', 'sunchang', 'sunchips', 'sunflower', 'sunflowers', 'sunkissed', 'sunkist', 'sunny', 'sunscreen', 'sunshine', 'super', 'superbowl', 'superfood', 'superfoods', 'superfruit', 'superherbs', 'superior', 'supersmart', 'supplement', 'supplements', 'supplier', 'supply', 'support', 'supporting', 'supports', 'surprise', 'survey', 'sushi', 'sustainable', 'sustained', 'sustaintability', 'svegannon', 'sw', 'swap', 'sweeper', 'sweet', 'sweetartscandy', 'sweeten', 'sweetened', 'sweeteners', 'sweets', 'swipes', 'swirl', 'swiss', 'sword', 'symptom', 'symptoms', 'syrup', 'syrups', 'system', 'systems', 'szeged', 't', 'ta', 'tab', 'table', 'tablespoon', 'tablespoons', 'tablet', 'tablets', 'tabs', 'taco', 'tacos', 'taffies', 'taffy', 'taffys', 'tagged', 'tagless', 'tahini', 'tahitian', 'tajin', 'take', 'takes', 'takis', 'tall', 'tallow', 'tamarind', 'tamarindo', 'tangerine', 'tangy', 'tank', 'tanoshii', 'tantalizing', 'tanzanian', 'tapatio', 'tape', 'tapioca', 'taps', 'target', 'taro', 'tarrito', 'tart', 'tartar', 'tartlets', 'tarts', 'taste', 'taster', 'tastes', 'tasting', 'tasty', 'tate', 'taza', 'tazas', 'tazo', 'tb', 'tbags', 'tbd', 'tbl', 'tblesppons', 'tbls', 'tblsp', 'tbs', 'tbsp', 'tbspn', 'tbsps', 'tbt', 'te', 'tea', 'teabag', 'teabags', 'teaballs', 'teacher', 'teamready', 'teapot', 'teas', 'teaspoon', 'teaspoonbaking', 'teaspoonful', 'teaspoonfuls', 'teaspoons', 'teavana', 'technology', 'teddy', 'teff', 'temp', 'temperature', 'temples', 'templess', 'tender', 'tenders', 'tennessee', 'tennis', 'tentacles', 'teriyaki', 'terra', 'terrific', 'test', 'tested', 'tests', 'tetley', 'tetra', 'texas', 'texaspete', 'tfl', 'tfusk', 'th', 'thai', 'than', 'thank', 'thanks', 'thanksgiving', 'that', 'thckng', 'the', 'theater', 'theatre', 'their', 'themed', 'then', 'there', 'thermometer', 'these', 'they', 'thiamin', 'thick', 'thicken', 'thickened', 'thickener', 'thicker', 'thin', 'think', 'thinness', 'thins', 'third', 'thirst', 'this', 'thissweetener', 'thomas', 'thousand', 'thread', 'threads', 'three', 'throat', 'throne', 'through', 'throwback', 'thru', 'ths', 'thymes', 'tic', 'tie', 'tier', 'tiered', 'tiers', 'tiesta', 'tiger', 'tim', 'time', 'timeless', 'times', 'tin', 'tinkyada', 'tins', 'tip', 'tips', 'tiptree', 'tirebolu', 'tissues', 'title', 'tm', 'to', 'toast', 'toasted', 'toaster', 'today', 'toddler', 'toddy', 'toffee', 'togetherness', 'tokyo', 'tom', 'tomato', 'tomatoes', 'toned', 'tongkat', 'tonnino', 'tons', 'tooth', 'toothbrush', 'toothpaste', 'toothpicks', 'tootsie', 'top', 'topically', 'topper', 'topping', 'toppings', 'topps', 'torani', 'tortilla', 'tortillas', 'toss', 'tossing', 'tostada', 'total', 'touch', 'tough', 'tournament', 'tow', 'towards', 'toxic', 'toxins', 'toy', 'toys', 'trac', 'trace', 'traces', 'track', 'tracks', 'trader', 'tradition', 'traditional', 'traeger', 'trail', 'trailblazer', 'training', 'trans', 'transfat', 'transfer', 'transforms', 'translucent', 'travel', 'tray', 'trays', 'treat', 'treatments', 'treats', 'tree', 'treekote', 'trees', 'trend', 'tri', 'trial', 'trials', 'triangle', 'triangles', 'trick', 'tricolor', 'trident', 'tried', 'tries', 'trillion', 'trim', 'trio', 'trios', 'triple', 'trizact', 'trophy', 'tropical', 'trple', 'true', 'truffle', 'truffles', 'truly', 'trusted', 'try', 'tsb', 'tsp', 'tspn', 'tsps', 'tub', 'tube', 'tubes', 'tubs', 'tulsi', 'tuna', 'turkey', 'turkish', 'turmeric', 'turn', 'turron', 'tutti', 'tweaker', 'twelve', 'twin', 'twinings', 'twinkies', 'twist', 'twisted', 'twists', 'twisty', 'twixx', 'twizzlers', 'two', 'type', 'types', 'typical', 'u', 'ufc', 'ug', 'uk', 'ultimate', 'ultra', 'unbleached', 'unboxed', 'unces', 'und', 'undecorated', 'unded', 'under', 'unexplainably', 'unexplainibly', 'unflavored', 'unicorn', 'unidades', 'unique', 'uniquely', 'unit', 'units', 'unitsbuy', 'universal', 'unlike', 'unlimited', 'unqzup', 'unscented', 'unscrew', 'unsharpened', 'unsliced', 'unswee', 'unsweetened', 'unt', 'until', 'untouched', 'unwrapped', 'up', 'upc', 'upgrade', 'upholds', 'upholstery', 'uplifting', 'uploaded', 'ups', 'upto', 'urban', 'us', 'usa', 'usda', 'use', 'uses', 'using', 'utah', 'utility', 'uv', 'uva', 'v', 'vacuum', 'vainilla', 'valentine', 'valentines', 'valley', 'valrhona', 'value', 'values', 'vaniglia', 'vanilla', 'var', 'variable', 'variants', 'variations', 'varied', 'variegated', 'varietals', 'varieties', 'variety', 'various', 'varities', 'vcap', 'vcaps', 'veces', 'veg', 'vegan', 'vegcapproduct', 'vegetable', 'vegetables', 'vegetarian', 'veggie', 'veggies', 'vegicapsules', 'velamints', 'velvet', 'vending', 'venice', 'venison', 'verified', 'vermicelli', 'vermont', 'vero', 'versafilter', 'versatile', 'versatility', 'version', 'very', 'vet', 'vibrant', 'vicks', 'victor', 'vienna', 'vietnamese', 'view', 'viking', 'vinegar', 'vinexpo', 'vino', 'vinta', 'vintage', 'vintner', 'vintners', 'vinyl', 'virbant', 'virtually', 'viscosity', 'vision', 'visit', 'vital', 'vitamin', 'vitamins', 'vivid', 'volcanoes', 'volluto', 'volt', 'volts', 'volume', 'volumes', 'voortman', 'votive', 'vr', 'vrty', 'vs', 'vwjli', 'w', 'wafels', 'wafer', 'wafers', 'waffle', 'waffles', 'waggoner', 'wagyu', 'wait', 'wall', 'wallet', 'walnut', 'walnuts', 'want', 'wap', 'warheads', 'warm', 'warmup', 'warning', 'warnings', 'was', 'wash', 'washes', 'washings', 'water', 'waterdrop', 'watermelon', 'waterproof', 'waterwetter', 'watkins', 'watt', 'watts', 'wavy', 'wax', 'way', 'ways', 'we', 'web', 'website', 'wedge', 'wedges', 'week', 'weekdays', 'weeks', 'weighs', 'weight', 'weird', 'weirdly', 'welcome', 'wellness', 'welsh', 'were', 'werthers', 'west', 'western', 'wet', 'wh', 'wharton', 'what', 'whataburger', 'wheat', 'wheels', 'when', 'whenever', 'where', 'whether', 'whey', 'which', 'while', 'white', 'whitespace', 'who', 'whole', 'wholefood', 'wholesale', 'wholesome', 'wht', 'why', 'wick', 'wide', 'wild', 'wildberry', 'will', 'willie', 'window', 'wine', 'winemaker', 'wings', 'winner', 'winning', 'winston', 'winter', 'wintergreen', 'wipes', 'wire', 'wireless', 'wisconsin', 'with', 'withering', 'within', 'without', 'wkrrp', 'wks', 'wned', 'wolfgang', 'women', 'won', 'wonder', 'wonderful', 'wonton', 'wood', 'wooden', 'woodstock', 'words', 'workout', 'workouts', 'works', 'world', 'worm', 'worms', 'would', 'woven', 'wrap', 'wrapped', 'wrappers', 'wraps', 'wt', 'wv', 'ww', 'www', 'wwwpurelifewater', 'wyler', 'x', 'xaa', 'xbuldak', 'xhot', 'xl', 'xp', 'xplosive', 'xpouch', 'xspicy', 'xspixy', 'xthe', 'xyloburst', 'y', 'yard', 'yards', 'yd', 'yds', 'year', 'years', 'yearsasted', 'yearscarbonated', 'yearsnutribiotic', 'yeast', 'yellow', 'yerba', 'yes', 'yf', 'yield', 'yields', 'yl', 'ymvt', 'yodels', 'yoga', 'yogi', 'yogurt', 'yoreelves', 'you', 'young', 'your', 'youre', 'yr', 'yrs', 'yrsaged', 'ys', 'yum', 'yummy', 'yupanqui', 'yuzu', 'z', 'za', 'zapp', 'zero', 'zesta', 'zested', 'zinc', 'zip', 'ziploc', 'ziti', 'zm', 'zo', 'zolli', 'zombie', 'zones', 'zuko', 'zutaten']\n",
            "\n",
            "---\n",
            "Analysis: Please review this list carefully. We will use it to identify all variations of weight (g, oz, kg, lb) and volume (ml, l, floz).\n"
          ]
        }
      ],
      "source": [
        "# -- 2.2: Discovering All Potential Units (Weight & Volume) --\n",
        "\n",
        "print(\"Searching for all number-unit patterns in the dataset...\")\n",
        "\n",
        "# This regex finds any number (integer or decimal) followed by a word (the potential unit).\n",
        "# \\b is a word boundary, ensuring we don't just grab parts of words.\n",
        "# It captures the number in group 1 and the unit in group 2.\n",
        "# We add a condition to make sure the \"unit\" is at least one character long.\n",
        "unit_pattern = re.compile(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]{1,})\\b')\n",
        "\n",
        "# Apply this regex to every row in the 'catalog_content' column.\n",
        "# .str.findall() will return a list of all (number, unit) tuples for each row.\n",
        "# .dropna() removes any rows where catalog_content might be null.\n",
        "all_matches = combined_df['catalog_content'].str.findall(unit_pattern).dropna()\n",
        "\n",
        "# Now, let's collect every unique unit found across the entire dataset.\n",
        "discovered_units = set()\n",
        "for matches_in_row in all_matches:\n",
        "    for number, unit in matches_in_row:\n",
        "        # We add a simple filter to avoid purely numeric \"units\" if any slip through\n",
        "        if not unit.isnumeric():\n",
        "            discovered_units.add(unit.lower()) # Use .lower() to treat 'G' and 'g' as the same\n",
        "\n",
        "# Sort the list for cleaner viewing\n",
        "sorted_units = sorted(list(discovered_units))\n",
        "\n",
        "print(f\"\\nDiscovered {len(sorted_units)} unique potential units.\")\n",
        "print(\"Here is the complete list:\")\n",
        "print(sorted_units)\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"Analysis: Please review this list carefully. We will use it to identify all variations of weight (g, oz, kg, lb) and volume (ml, l, floz).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx_yzDi8Ajlx",
        "outputId": "76e27058-2f49-4b80-f2eb-fd114dfec8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing the discovered units and grouping them into categories...\n",
            "\n",
            "--- Verification of Unit Groups ---\n",
            "\n",
            "WEIGHT units found in data (24):\n",
            "['g', 'gr', 'gram', 'gramos', 'grams', 'kg', 'kgs', 'kilo', 'kilogram', 'kilograms', 'lb', 'lbs', 'libras', 'mcg', 'mg', 'milligram', 'milligrams', 'onzas', 'ounce', 'ounces', 'oz', 'pound', 'pounds', 'quilogramas']\n",
            "\n",
            "VOLUME units found in data (26):\n",
            "['cup', 'cups', 'fl', 'floz', 'fluid', 'gal', 'gallon', 'gallons', 'galon', 'l', 'liter', 'liters', 'litre', 'litres', 'litros', 'mililiters', 'milliliter', 'milliliters', 'ml', 'pint', 'pints', 'pt', 'qt', 'qts', 'quart', 'quarts']\n",
            "\n",
            "DIMENSION units found in data (11):\n",
            "['centimeter', 'centimeters', 'cm', 'feet', 'ft', 'in', 'inch', 'inches', 'millimeter', 'millimeters', 'mm']\n",
            "\n",
            "COUNT units found in data (37):\n",
            "['bag', 'bags', 'bottle', 'bottles', 'box', 'boxes', 'btl', 'bx', 'can', 'cans', 'caps', 'capsule', 'capsules', 'cnt', 'count', 'ct', 'doz', 'dozen', 'dz', 'ea', 'each', 'pack', 'packs', 'pc', 'pck', 'pcs', 'piece', 'pieces', 'pk', 'pkg', 'roll', 'rolls', 'sachet', 'sachets', 'tablet', 'tablets', 'tabs']\n",
            "\n",
            "\n",
            "Analysis: These clean, verified lists will be the foundation for our precise extraction rules.\n"
          ]
        }
      ],
      "source": [
        "# -- 2.3: Analyze and Define Unit Groups --\n",
        "\n",
        "print(\"Analyzing the discovered units and grouping them into categories...\")\n",
        "\n",
        "# From our manual review of the 'sorted_units' list, we define our whitelists.\n",
        "# We are creating these lists based on the evidence from the data.\n",
        "\n",
        "# -- WEIGHT UNITS --\n",
        "# We include singular, plural, and common abbreviations.\n",
        "WEIGHT_UNITS = [\n",
        "    'g', 'gr', 'gram', 'grams', 'gramos',\n",
        "    'kg', 'kgs', 'kilo', 'kilogram', 'kilograms', 'quilogramas',\n",
        "    'oz', 'ounce', 'ounces', 'onza', 'onzas',\n",
        "    'lb', 'lbs', 'libra', 'libras', 'pound', 'pounds',\n",
        "    'mg', 'milligram', 'milligrams',\n",
        "    'mcg', 'microgram', 'micrograms'\n",
        "]\n",
        "\n",
        "# -- VOLUME UNITS --\n",
        "VOLUME_UNITS = [\n",
        "    'ml', 'milliliter', 'milliliters', 'mililiters',\n",
        "    'l', 'liter', 'liters', 'litre', 'litres', 'litros',\n",
        "    'floz', 'fl', 'fluid', # 'fluid' is often followed by 'oz' but can be standalone\n",
        "    'gal', 'gallon', 'gallons', 'galon',\n",
        "    'qt', 'qts', 'quart', 'quarts',\n",
        "    'pt', 'pint', 'pints',\n",
        "    'cup', 'cups'\n",
        "]\n",
        "\n",
        "# -- DIMENSION UNITS --\n",
        "DIMENSION_UNITS = [\n",
        "    'cm', 'centimeter', 'centimeters',\n",
        "    'mm', 'millimeter', 'millimeters',\n",
        "    'in', 'inch', 'inches',\n",
        "    'ft', 'feet'\n",
        "]\n",
        "\n",
        "# -- COUNT/PACK UNITS --\n",
        "# These are units that imply a quantity of items.\n",
        "COUNT_UNITS = [\n",
        "    'pack', 'packs', 'pk', 'pkg', 'pck',\n",
        "    'count', 'ct', 'cnt',\n",
        "    'ea', 'each',\n",
        "    'pc', 'pcs', 'piece', 'pieces',\n",
        "    'dozen', 'doz', 'dz',\n",
        "    'roll', 'rolls',\n",
        "    'can', 'cans',\n",
        "    'bottle', 'bottles', 'btl',\n",
        "    'bag', 'bags',\n",
        "    'box', 'boxes', 'bx',\n",
        "    'sachet', 'sachets',\n",
        "    'tablet', 'tablets', 'tabs',\n",
        "    'capsule', 'capsules', 'caps'\n",
        "]\n",
        "\n",
        "# Now, let's filter our big 'sorted_units' list to see which of our chosen units were actually found\n",
        "found_weight_units = [unit for unit in sorted_units if unit in WEIGHT_UNITS]\n",
        "found_volume_units = [unit for unit in sorted_units if unit in VOLUME_UNITS]\n",
        "found_dimension_units = [unit for unit in sorted_units if unit in DIMENSION_UNITS]\n",
        "found_count_units = [unit for unit in sorted_units if unit in COUNT_UNITS]\n",
        "\n",
        "print(\"\\n--- Verification of Unit Groups ---\")\n",
        "print(f\"\\nWEIGHT units found in data ({len(found_weight_units)}):\")\n",
        "print(found_weight_units)\n",
        "\n",
        "print(f\"\\nVOLUME units found in data ({len(found_volume_units)}):\")\n",
        "print(found_volume_units)\n",
        "\n",
        "print(f\"\\nDIMENSION units found in data ({len(found_dimension_units)}):\")\n",
        "print(found_dimension_units)\n",
        "\n",
        "print(f\"\\nCOUNT units found in data ({len(found_count_units)}):\")\n",
        "print(found_count_units)\n",
        "\n",
        "print(\"\\n\\nAnalysis: These clean, verified lists will be the foundation for our precise extraction rules.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfelPPFcAjcq",
        "outputId": "72333f5b-ae9c-4b4d-8053-440a7cf6b0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting the context of our verified keywords to finalize extraction strategy...\n",
            "\n",
            "=========================\n",
            "--- Inspecting for: Brand Keyword ---\n",
            "=========================\n",
            "Found 5 rows containing at least one of the 'Brand Keyword' keywords.\n",
            "Showing 5 random samples:\n",
            "\n",
            "--- [Sample Record ID: 188616] ---\n",
            "Item Name: 50 Jamaican Sorrel Seeds, Florida Cranberry, Indian Roselle, Hibiscus Sabdariffa\n",
            "Bullet Point 1: Country/Region Of Manufacture:Jamaica, Mpn:Florida Cranberry Indian ,Roselle,Hibisc\n",
            "Bullet Point 2: Brand:Hibiscus Sabdariffa\n",
            "Bullet Point 3: Model:Sorrel\n",
            "Value: 50.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 42177] ---\n",
            "Item Name: Eden Foods Organic Garbanzo Beans - Case of 12 - 29 oz.\n",
            "Product Description: Specification<br>Brand:EDEN FOODS<br>Dairy Free:Yes<br>Fair Trade:No<br>Gluten Free:Yes<br>GMO Free?:GMO Free<br>Ingredients:ORGANIC GARBANZO BEANS;WATER;KOMBU SEAWEED<br>Kosher:Yes<br>Organic:Yes<br>Selling Units:case<br>Size:29 OZ<br>Vegan:No<br>Wheat Free:Yes<br>Yeast Free:Yes<br>Details<br>These plump, round, golden beans are perfect on salad greens, in marinated and pasta salads, soups and dips. Blend with tahini, lemon juice and garlic for hummus. High in healthy fiber and folate B9, plus a good source of protein and magnesium. No salt added.<br>Ingredients:ORGANIC GARBANZO BEANS;WATER;KOMBU SEAWEED<br>\n",
            "Value: 348.0\n",
            "Unit: Ounce\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 181651] ---\n",
            "Item Name: #2274 Mexico Pure Vanilla Blend Molina Vainilla, 16.8 Oz Extract Classic Bake\n",
            "Bullet Point 1: Brand:Molina, Country/Region Of Manufacture:Mexico, Featured Refinements:Vanilla Extract\n",
            "Bullet Point 2: Spice Type:Vanilla, Form:Extract, Expiration Year:2020\n",
            "Bullet Point 3: Size:16 ounces, Cuisine:Mexican, Expiration Month:July\n",
            "Product Description: Product Description Molina Vanilla does not contain coumarin. It containes vanillin, an artificial flavor (or flavoring). Molina is the pioneer of the Mexican Vanillas since 1944Molina Vanilla is made with high quality ingredients, and it's original formula, helps to give our product a natural vanilla flavor. It will give your cakes, bakery, frozen or frozen snows, trowels, yogurts, drinks, desserts, candies, etc., an additional flavor. Molina Vanilla has an incomparable flavor. It's the favorite kind of Vanilla in Mexico and the United States. A blend of Mexico's finest pure vanilla and vanillin. Ingredients: Water, 2 Pure Vanilla Extract, 1.8 Ethyl Acohol, Propylene Gycol, Vanillin, Ethyl Vanillin, Caramel Color and Potassium Sorbate (as preservative) Molina Vanilla is produced by: Productos Uvavina SA de CV de Zapopan, Jalisco Mexico. A Kosher Pareve productSee my other itemsSee my other items<br><br><b>Exported By ExportYourStore</b>\n",
            "Value: nan\n",
            "Unit: None\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 168638] ---\n",
            "Item Name: Jyoti Entree Saag Paneer Pouch\n",
            "Product Description: Specification<br>Brand:JYOTI CUISINE INDIA<br>Dairy Free:No<br>Fair Trade:No<br>Gluten Free:Yes<br>GMO Free?:GMO Free<br>Ingredients:No<br>Kosher:No<br>Organic:No<br>Selling Units:case<br>Size:10 OZ<br>Vegan:No<br>Wheat Free:No<br>Yeast Free:Yes<br>Details<br>Fine chopped creamy spinach (Saag) with Paneer Cheese chunks. Gingery hot and very flavorful side dish or pasta sauce.<br>Ingredients: SPINACH;FILTERED WATER;PANEER CHEESE;MILK;ONION;CREAM;BUTTER;GINGER;CORN MEAL;GARLIC;ALMOND OIL;NUTS;SPICES;SEA SALT<br>\n",
            "Value: 1.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 252765] ---\n",
            "Item Name: Bare, Fruit Snacks Cinnamon Apple Organic, 3 Ounce12\n",
            "Bullet Point 1: 100% Organic\n",
            "Bullet Point 2: Gluten Free\n",
            "Bullet Point 3: Dairy Free\n",
            "Bullet Point 4: Wheat Free\n",
            "Bullet Point 5: GMO Free\n",
            "Product Description: Specification<br>Brand:BARE FRUIT<br>Organic:100% Organic<br>Gluten Free:Yes<br>Dairy Free:Yes<br>Yeast Free:No<br>Wheat Free:Yes<br>Vegan:No<br>Kosher:Yes<br>Fair Trade:No<br>GMO Free:Yes<br>Size:3 OZ<br>Country of Origin:United States<br>Details<br>BARE FOOD ORGANIC CINNAMON APPLE CHIPS ARE AN EXCELLENT GLUTEN-FREE, FAT FREE CHOICE FOR A SNACK. THESE APPLE CHIPS ARE BAKED FROM CRUNCHY, REAL APPLES AND DO NOT CONTAIN OIL, ADDED SUGAR OR PRESERVATIVES. BARE FOOD ORGANIC APPLE CHIPS ARE ALSO A GOOD SOURCE OF FIBER, NON-GMO AND PACKAGED FOR YOUR CONVENIENCE IN A 3 OZ. POUCH. THERE ARE ONLY 110 CALORIES IN EACH ? CUP SERVING OF APPLE CHIPS AND EACH BARE FOOD ORGANIC CINNAMON APPLE CHIPS 3 OZ. POUCH CONTAIN ABOUT THREE SERVINGS OF PRODUCT. PLEASE SEE NUTRITIONAL FACTS PANEL FOR PRODUCT WARNINGS.<br>Ingredients: ORGANIC APPLES;ORGANIC CINNAMON<br>\n",
            "Value: 36.0\n",
            "Unit: Ounce\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "=========================\n",
            "--- Inspecting for: Weight Keywords ---\n",
            "=========================\n",
            "Found 76945 rows containing at least one of the 'Weight Keywords' keywords.\n",
            "Showing 5 random samples:\n",
            "\n",
            "--- [Sample Record ID: 203370] ---\n",
            "Item Name: King Arthur Baking Company Pull-Apart Garlic Bread Mix Kit 15.25 oz., Baking Mix - Ready in 1 hour\n",
            "Bullet Point 1: Ready in 1 hour & everything you need is right in the box!\n",
            "Bullet Point 2: This pull-apart garlic bread mix kit includes all the dry ingredients needed right in the box - even the yeast, mix-ins, and topping! Just add water and butter and you'll have tasty garlic bread on the table in no time.\n",
            "Bullet Point 3: This 15.25 oz mix kit makes one 8\" square or 9\" round pull-apart garlic bread. Our mixes are carefully crafted in our test kitchen through meticulous taste-testing; it’s a tough job, but we’re up to the challenge.\n",
            "Bullet Point 4: King Arthur Baking Company is a 100% Employee-Owned Company and a founding B Corporation.\n",
            "Bullet Point 5: We are King Arthur Baking Company. Our name and logo reflect who we've always been and always will be: bakers who are committed to spreading the simple joy of baking\n",
            "Value: 15.25\n",
            "Unit: Ounce\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 219958] ---\n",
            "Item Name: Bean Bites | Sizzlin Schezwan Lentil Crisp 3.53 oz (100 g) PACK of 6 | Mini Poppadom Snack | Round Crunchy Crisps | Earthy Schezwan Taste | Heat in Oven (60s), Plant Based Protein by Pride of India\n",
            "Bullet Point 1: Subtle Schezwan Mini Poppadom: Sizzle with excitement as you experience the crunchy flavor of Schezwan's rich culinary tradition with our Sizzlin Schezwan Lentil Crisps! Crafted with wholesome lentils and the subtle heat of Schezwan seasoning and spices, each delicious bite delivers a bold flavor in every crunch, leaving you craving more.\n",
            "Bullet Point 2: Perfect Keto Crunch: Enjoy guilt-free indulgence with our Sizzlin Schezwan Mini Poppadoms, the ultimate snack for your keto lifestyle. Specially crafted to curb cravings, these mini poppadoms are packed with the wholesome goodness of lentils and a mild schezwan kick. Enjoy as quick keto-friendly snacks or a pairing companion to keto dips, completing your healthy and satisfying snacking experience.\n",
            "Bullet Point 3: Quick & Oven-Friendly: Our lentil crisps are incredibly easy to prepare, making them the perfect snack in no time! Simply pop them into the oven at 350°F for about 60 seconds, and they’re ready to enjoy. Made from premium lentils, enjoy their light, crisp texture, natural earthiness, and beautifully balanced flavor as an ideal treat to satisfy your cravings.\n",
            "Bullet Point 4: Versatile Snack: Enjoy the Schezwan-flavored lentil crisps as an easy, healthy snack anytime. These perfectly mild, spicy chili crisps can be paired with your favorite dips, sauces, and spreads for a gourmet experience. Enjoy them with hummus, lemon dips, queso, or fruit salsa, offering endless possibilities for fantastic snacking experiences.\n",
            "Bullet Point 5: Artisanal Craftsmanship: Experience the artistry behind every batch of Sizzlin Schezwan Lentil Crisps. Crafted with precision and care, these mini poppadoms feature the perfect balance of ingredients, showcasing a dedication to quality and flavor. Each bite offers a wholesome sundried snack experience, blending craftsmanship with indulgence.\n",
            "Bullet Point 6: Schezwan Tale: Meet Schezwan Lentil Crisp, where the feisty Chinese chili and the humble lentil unite as unlikely friends, creating a snack bursting with flavor and camaraderie in every bite. Experience the delightful fusion of spice and innocence in this irresistible crunchy snack.\n",
            "Product Description: Redefine healthy snacking with Bean Bites Sizzlin Schezwa Lentil Crisps! A unique and wholesome snack experience that blends the earthy goodness of lentils with a subtle hint of schezwan seasoning. These mini poppadoms are vegan, gluten-free, and keto-friendly, perfect for every snacking occasion. Enjoy guilt-free, oil-free indulgence by simply baking them for a few seconds for the ultimate crunchy treat. Lightly seasoned for a beautifully balanced flavor and crispy texture, they pair perfectly with dips, sauces, and spreads. Ready in just 60 seconds, they’re the ideal companion for your favorite snacking moments!\n",
            "Value: 21.18\n",
            "Unit: Ounce\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 70277] ---\n",
            "Item Name: Gatorlyte Zero Strawberry Kiwi, 20 Fl Oz Bottle (Pack of 12)\n",
            "Bullet Point: Gatorlyte Zero Strawberry Kiwi 20oz\n",
            "Value: 240.0\n",
            "Unit: Fl Oz\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 66059] ---\n",
            "Item Name: Colavita Balsamic Glaze - Italian Import Squeeze Bottle, Perfect for Enhancing Flavors, 8.5 Fl Oz (Pack of 1)\n",
            "Bullet Point 1: Authentic Italian Quality: Colavita Balsamic Glaze is crafted in Italy using premium balsamic vinegar from Modena, delivering rich, balanced flavor.\n",
            "Bullet Point 2: Thick & Velvety Texture: Perfect for drizzling over salads, grilled meats, vegetables, cheeses, and desserts for a gourmet touch.\n",
            "Bullet Point 3: Sweet & Tangy Flavor Profile: Offers a delightful balance of sweetness and acidity, enhancing both savory and sweet dishes.\n",
            "Bullet Point 4: Convenient Squeeze Bottle: The 8.5fl oz plastic bottle features an easy-to-use squeeze design for precise application without mess.\n",
            "Bullet Point 5: Versatile Culinary Use: Ideal for glazing meats, topping caprese salads, adding depth to roasted vegetables, or drizzling over strawberries and ice cream.\n",
            "Bullet Point 6: All-Natural Ingredients: Made without artificial flavors, colors, or preservatives to ensure an authentic, high-quality glaze.\n",
            "Bullet Point 7: Product of Italy: Experience the tradition, quality, and excellence of Italian balsamic craftsmanship with Colavita.\n",
            "Value: 8.5\n",
            "Unit: Fl Oz\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 80721] ---\n",
            "Item Name: Roland: Black Truffle Oil 1.86 Oz (12 Pack)\n",
            "Value: 12.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "=========================\n",
            "--- Inspecting for: Volume Keywords ---\n",
            "=========================\n",
            "Found 5030 rows containing at least one of the 'Volume Keywords' keywords.\n",
            "Showing 5 random samples:\n",
            "\n",
            "--- [Sample Record ID: 261085] ---\n",
            "Item Name: AriZona Beverages Lemon Tea, 23 oz\n",
            "Bullet Point 1: 100 percentage Natural Ingredients\n",
            "Bullet Point 2: Flavored Tea\n",
            "Bullet Point 3: The package dimension of the product is 3.9\"L x 3.9\"W x 7.9\"H\n",
            "Bullet Point 4: Country of origin is United States\n",
            "Value: 23.0\n",
            "Unit: Fl Oz\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 132643] ---\n",
            "Item Name: Peet's Coffee, Medium Roast Espresso Capsules, Compatible with Nespresso Original Machine - Crema Scura Intensity 9, 50 Count (5 Boxes of 10 Espresso Capsules)\n",
            "Bullet Point 1: Contains five (5) Boxes of 10 Peet's Crema Scura Espresso - Intensity 9 Medium Roast Coffee Single Cup Espresso Capsules (50 Espresso Capsules Total)\n",
            "Bullet Point 2: Flavor and Roast: Medium Roast - Intensity 9. Thick and luxurious espresso with nutty notes balanced by a creamy, enduring finish. 100% Arabica Coffee\n",
            "Bullet Point 3: Peet’s Espresso Capsules are compatible with the Nespresso Original Machines*, Essenza Mini, Essenza Plus, Pixie, CitiZ, Lattissima, KitchenAid, and Creatista Nespresso Original machines.* Not compatible with Nespresso Vertuo machines. *Peet's is not affiliated with the Nespresso brand.\n",
            "Bullet Point 4: Recyclable: Peet’s aluminum capsules are recyclable through our mail-back program. Each aluminum capsule is sealed to preserve that delicious aroma and flavor for an intense espresso experience\n",
            "Bullet Point 5: How to Brew: Peet's capsules work with Ristretto (0.85 OZ / 25 ml) or Espresso (1.35 OZ / 40 ml) pulls on your brewer.\n",
            "Value: 50.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 180331] ---\n",
            "Item Name: L'Oréal Paris EverSleek Sulfate Free Keratin Caring Conditioner, 8.5 fl. oz.\n",
            "Bullet Point 1: For Chemically Processed Hair\n",
            "Bullet Point 2: Sulfate Free\n",
            "Bullet Point 3: No Silicones\n",
            "Bullet Point 4: Sunflower Oil\n",
            "Bullet Point 5: No Harsh Salts\n",
            "Value: 8.5\n",
            "Unit: Fluid Ounce\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 298413] ---\n",
            "Item Name: Kirkland Signature Pure Vanilla, 16 Ounce\n",
            "Bullet Point 1: Product Type:Grocery\n",
            "Bullet Point 2: Item Package Dimension:6.0 \" L X5.0 \" W X 4.0 \" H\n",
            "Bullet Point 3: Item Package Weight:18.5 oz\n",
            "Bullet Point 4: Country Of Origin: United States\n",
            "Value: 16.0\n",
            "Unit: Fl Oz\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 296747] ---\n",
            "Item Name: Hershey's Milk Chocolate Kisses, 56 Oz.\n",
            "Bullet Point 1: Product Type:Grocery\n",
            "Bullet Point 2: Item Package Dimension:6.0 \" L X5.0 \" W X4.0 \" H\n",
            "Bullet Point 3: Item Package Weight:3.58 lbs\n",
            "Bullet Point 4: Country Of Origin: United States\n",
            "Bullet Point 5: Model Number : 00-Ngy2Te-80\n",
            "Value: 56.0\n",
            "Unit: ounce\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "=========================\n",
            "--- Inspecting for: Pack/Count Keywords ---\n",
            "=========================\n",
            "Found 93281 rows containing at least one of the 'Pack/Count Keywords' keywords.\n",
            "Showing 5 random samples:\n",
            "\n",
            "--- [Sample Record ID: 109904] ---\n",
            "Item Name: Thames & Kosmos Candy Science Experiment Kits | 2-Pack Bundle | Gummy Candy Lab & Super Duper Bubble Gum Lab | Sweet Science STEM Activity Kits | Make Your Own Yummy Candy Treats | Learn Chemistry\n",
            "Bullet Point 1: 2-pack bundle of candy-making STEM kits: (1) Super Duper Bubble Gum Lab; (1) Gummy Candy Lab\n",
            "Bullet Point 2: Make your own delicious bubble gum in three different flavors: watermelon, orange, and classic bubble gum!\n",
            "Bullet Point 3: Cook up yummy gummy candies in fun shapes with lemon and cherry flavors!\n",
            "Bullet Point 4: Learn about the scientific properties of natural polymers and elastic and gel materials.\n",
            "Bullet Point 5: Food ingredients included, as well as bags and stickers to package your yummy treats!\n",
            "Product Description: Science is sweet with this 2-pack bundle of candy-making STEM kits! Receive one unit each of Super Duper Bubble Gum Lab and Gummy Candy Lab and get started on some delicious science fun! Super Duper Bubble Gum Lab is the ultimate bubble gum making kit. With it, you'll make your own delicious bubble gum in three different flavors: watermelon, orange, and classic bubble gum. Mix up your gum base, sweeten it with sugar, add your flavoring of choice, and voila: You've got your own yummy bubble gum. With Gummy Candy Lab, you can mold your own delicious gummy candies with lemon or cherry flavors using a natural gelatin-like ingredient called carrageenan that comes from seaweed! Shapes include bears, fruit, dolphins, and dinosaurs. You can even add citric acid to make sour gummies! Food ingredients are included with both kits. You'll also get storage bags and fun stickers so that you can wrap up your candy creations and give them away as personalized gifts to friends and family! Bonus: as you make your yummy treats and conduct experiments with them, you'll also learn about the scientific properties of natural polymers and elastic and gel materials.\n",
            "Value: 2.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 111660] ---\n",
            "Item Name: Dastony Organic Raw Black Sesame Butter, 8 oz | Only One Ingredient | Vegan, Paleo and Keto Friendly, Non GMO, Gluten-free - Pack of 1\n",
            "Bullet Point 1: Only One Premium Organic Ingredient: Dastony Black Sesame Seed Butter is made from the finest, certified organic sesame seeds. No artificial flavors or synthetic colors.\n",
            "Bullet Point 2: Healthy Seed Butter Option: Dastony Black Sesame Seed Butter is a nutritious choice, offering a wealth of essential nutrients and beneficial fats in every serving.\n",
            "Bullet Point 3: Distinctive Nutty Flavor: Indulge in the distinctive nutty taste of black sesame seeds, adding depth and complexity to your favorite dishes.\n",
            "Bullet Point 4: Versatile Culinary Ingredient: Whether spread on toast, blended into smoothies, or used in savory sauces, Dastony Black Sesame Seed Butter adds a unique twist to a variety of recipes.\n",
            "Bullet Point 5: USDA Organic, stone ground, vegan, raw, dairy-free, soy-free, paleo, kosher, and gluten-free.\n",
            "Product Description: Indulge in the rich, nutty flavor of Dastony Black Sesame Seed Butter – a nutritious and delicious spread that's as versatile as it is wholesome. Crafted from raw black sesame seeds, this healthy seed butter is a gluten-free delight, perfect for those with dietary restrictions or seeking a nutritious alternative. Our Black Sesame Seed Butter is a testament to purity and quality, with no added sugar or preservatives. Each jar is packed with the natural goodness of raw sesame seeds, carefully stone-ground to preserve their nutrients and enhance their flavor profile. As a gluten-free seed butter, our Black Sesame Seed Butter offers a guilt-free indulgence for those looking to embrace a healthier lifestyle. Whether spread on toast, drizzled over yogurt, or used as a dip for fruits and vegetables, its velvety texture and distinctive nutty taste will elevate any snack or meal. Upgrade your pantry with Dastony Black Sesame Seed Butter – a nutritious and flavorful spread that's perfect for any occasion. With its wholesome ingredients and unparalleled taste, it's sure to become a staple in your kitchen.\n",
            "Value: 8.0\n",
            "Unit: Ounce\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 158482] ---\n",
            "Item Name: Stacy's Pita Chips, Simply Naked, 1.5-ounce Bags (Pack of 12)12\n",
            "Value: 18.0\n",
            "Unit: Fl Oz\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 143228] ---\n",
            "Item Name: Big Dot of Happiness Pumpkin - Mini Candy Bar Wrapper Stickers - Fall, Halloween or Thanksgiving Party Small Favors - 40 Count\n",
            "Bullet Point 1: Pumpkin Patch Mini Candy Bar Wrappers INCLUDES 40 candy stickers, perfect for styling an adorable pumpkin candy buffet or unique fall party or Thanksgiving favors.\n",
            "Bullet Point 2: Pumpkin Patch mini candy bar wrappers MEASURE 1.25” wide x 2.75” high and will quickly add a personal touch to all your sweet treats. It is easy to wrap miniature candy bars with these festive Pumpkin Patch stickers!\n",
            "Bullet Point 3: EASY PARTY DECORATIONS: Pumpkin Patch mini candy bar sticker labels are an easy party decoration to add to your list of party supplies. Scatter decorated miniature candy bars down your dining tables, package in small gift bags as a party favor or display in a pretty bowl at your candy buffet. Get creative with your pumpkin DIY fall and Halloween party decoration ideas!\n",
            "Bullet Point 4: PREMIUM PARTY SUPPLIES: Pumpkin Patch mini candy bar labels are professionally printed on sticker paper with a photo-like shine. They are individually inspected and carefully packaged by hand. Simply wrap each sticker around a miniature chocolate candy bar.\n",
            "Bullet Point 5: MADE IN THE USA: Pumpkin Patch - Fall, Halloween or Thanksgiving Party Mini Candy Bar Wrappers Party Favors are designed and manufactured at our Wisconsin facility using materials that are Made in the USA. Please Note: Candies are not included but are available at your local grocery store.\n",
            "Product Description: One of the easiest (and tastiest) do-it-yourself party favors available, our original pumpkin themed mini candy bar wrapper sticker labels are a must-have for any fall, Halloween or Thanksgiving party. Simply add these mini candy bar wrappers to miniature candy bars and easily create a party favor beautiful enough to be scattered in the middle of your tables or placed in a bowl at the cake table as an extra treat. Your guests will love the adorable design. Mini candy bar wrappers are sold in a set of 40, so be sure to order enough for everyone because this is one party favor no one can resist.\n",
            "Value: 40.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "--- [Sample Record ID: 267374] ---\n",
            "Item Name: Bestpresso Coffee for Nespresso Original Machine 120 pods Certified Genuine Espresso Chocolate Blend (Medium Intensity) Pods Compatible with Nespresso Original 60 Days Satisfaction Guarantee\n",
            "Bullet Point 1: ✔ 60 Days Satisfaction Guarantee. . Our Pods are not compatible with VertouLine Machines.\n",
            "Bullet Point 2: Kosher certification: this product is certified kosher by the orthodox union.\n",
            "Bullet Point 3: Coffee capsules compatible with Nespresso Original coffee machines\n",
            "Bullet Point 4: High quality 100% natural & unique espresso in convenient Nespresso compatible pods 6 boxes, containing 20 capsules each, 120 capsules total\n",
            "Bullet Point 5: No preservatives, no sugar or flavoring added, Over 50% Rainforest Alliance Certified Sustainable coffee in support of small coffee producers. Product from Spain\n",
            "Value: 120.0\n",
            "Unit: Count\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "--- Section 2 Complete ---\n",
            "Analysis: Review the samples above to confirm regex patterns. This completes our EDA.\n"
          ]
        }
      ],
      "source": [
        "# -- 2.4: Inspecting Keyword Context (V5 - Final Corrected Version) --\n",
        "\n",
        "print(\"Inspecting the context of our verified keywords to finalize extraction strategy...\")\n",
        "\n",
        "def inspect_content(df, keywords, title, num_samples=5):\n",
        "    \"\"\"\n",
        "    Finds and prints random samples of 'catalog_content' containing specific keywords.\n",
        "    Uses the correct column name 'sample_id'.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*25}\\n--- Inspecting for: {title} ---\\n{'='*25}\")\n",
        "\n",
        "    pattern = r'\\b(' + '|'.join(map(re.escape, keywords)) + r')\\b'\n",
        "\n",
        "    # This warning is expected and can be ignored for this EDA step.\n",
        "    relevant_rows = df[df['catalog_content'].str.contains(pattern, case=False, na=False)]\n",
        "\n",
        "    if relevant_rows.empty:\n",
        "        print(f\"No samples found for keywords: {keywords}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(relevant_rows)} rows containing at least one of the '{title}' keywords.\")\n",
        "\n",
        "    sample_size = min(num_samples, len(relevant_rows))\n",
        "    if sample_size > 0:\n",
        "        print(f\"Showing {sample_size} random samples:\\n\")\n",
        "\n",
        "        sample_indices = relevant_rows.sample(n=sample_size, random_state=101).index\n",
        "\n",
        "        for idx in sample_indices:\n",
        "            row = df.loc[idx]\n",
        "\n",
        "            # THE FIX: Use 'sample_id' instead of 'id'\n",
        "            print(f\"--- [Sample Record ID: {row['sample_id']}] ---\")\n",
        "            print(row['catalog_content'])\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "# --- Run Inspections ---\n",
        "# 1. For Brand\n",
        "inspect_content(combined_df, ['brand:'], \"Brand Keyword\")\n",
        "\n",
        "# 2. For Weight\n",
        "inspect_content(combined_df, ['g', 'oz', 'kg', 'lb'], \"Weight Keywords\")\n",
        "\n",
        "# 3. For Volume\n",
        "inspect_content(combined_df, ['ml', 'l', 'floz', 'gallon'], \"Volume Keywords\")\n",
        "\n",
        "# 4. For Pack Size / Count\n",
        "inspect_content(combined_df, ['pack', 'count', 'piece', 'bottle'], \"Pack/Count Keywords\")\n",
        "\n",
        "print(\"\\n\\n--- Section 2 Complete ---\")\n",
        "print(\"Analysis: Review the samples above to confirm regex patterns. This completes our EDA.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lto0Dsh19Zv1",
        "outputId": "3c1093f2-687f-4c30-a6d6-bcd4daa97df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inspecting for duplicate image links as per your suggestion ---\n",
            "\n",
            "Found 150000 total rows.\n",
            "Found 140587 unique image links.\n",
            "Found 6991 image links that are used more than once.\n",
            "\n",
            "--- Top 10 Most Duplicated Image Links ---\n",
            "image_link\n",
            "https://m.media-amazon.com/images/I/51m1gdQJW2L.jpg    97\n",
            "https://m.media-amazon.com/images/I/71LRdXdqc0L.jpg    31\n",
            "https://m.media-amazon.com/images/I/71brV+lqbRL.jpg    25\n",
            "https://m.media-amazon.com/images/I/21mMXLWiDOL.jpg    21\n",
            "https://m.media-amazon.com/images/I/61md5v6UPNL.jpg    21\n",
            "https://m.media-amazon.com/images/I/71FMi9tO3HL.jpg    19\n",
            "https://m.media-amazon.com/images/I/21l1ELDzJAL.jpg    16\n",
            "https://m.media-amazon.com/images/I/51DDKoa+mbL.jpg    15\n",
            "https://m.media-amazon.com/images/I/91RB11r3xSL.jpg    14\n",
            "https://m.media-amazon.com/images/I/71gtFKX66JL.jpg    14\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Investigating the most duplicated link: https://m.media-amazon.com/images/I/51m1gdQJW2L.jpg ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                    catalog_content  \\\n",
              "1203                                                                                                                                                                         Item Name: Manischewitz Soup Matzo Ball Jars, 1.5 lb\\nBullet Point: Kosher for Passover and all year round\\nValue: 24.0\\nUnit: Ounce\\n   \n",
              "2121    Item Name: Sweet Leaf Tea Pet Peach, 16 fl oz\\nBullet Point 1: Naturally caffeine free and All natural botanicals\\nBullet Point 2: Item Package Weight: 1.19 lb\\nBullet Point 3: Country Of Origin: United States\\nBullet Point 4: Item Package Dimension: 7.2399999926152\" L x 2.599999997348\" W x 2.59...   \n",
              "2203    Item Name: Blue Diamond Nut Thins Almonds Honey Cinnamon Cracker Snacks, 4.25 Ounce - 12 per case.\\nBullet Point: 4.25 Ounces\\nProduct Description: Nut thins are a unique, crispy and crunchy cracker loaded with delicious and nutritious pecans. They are the only crackers made with nuts and baked ...   \n",
              "2773                                                              Item Name: Organic Cranberry Pomegrante Juice 32 Ounces (Case of 12)\\nBullet Point: 32 Ounces\\nProduct Description: An Organic Apple, Cranberry and Pomegranate Juice Blend from Concentrates with Other Ingredients.\\nValue: 12.0\\nUnit: Count\\n   \n",
              "4677    Item Name: Peace Clusters and Flakes Cereal, Maple Pecan, 11 Ounce (Pack of 6)\\nBullet Point 1: Whole grain oat clusters, crispy corn flakes, pecans with real maple syrup\\nBullet Point 2: We add only premium all natural grains, nuts and fruits providing you with essential whole grains, fiber and...   \n",
              "...                                                                                                                                                                                                                                                                                                             ...   \n",
              "144557                                                                                                                                                          Item Name: Eden Foods Organic Apple Sauce, 25 Ounce - 12 per case.\\nBullet Point 1: Gluten Free\\nBullet Point 2: Kosher\\nValue: 12.0\\nUnit: Count\\n   \n",
              "144712                                                                                                                                                                                                         Item Name: R W Knudsen Organic Grapefruit Juice, 32 Ounce - 12 per case.\\nValue: 32.0\\nUnit: Ounce\\n   \n",
              "144721                                                                                                                                                                                                                                    Item Name: Taste Of Thai Noodle Qck Meal Peanut\\nValue: nan\\nUnit: None\\n   \n",
              "145196  Item Name: Organic White Jasmine Rice 25 lbs. bag\\nBullet Point: Description | Ingredients | Cooking Instructions | No Additives |Oil-Free| Allergen Free ||| |||| |\\nProduct Description: Save On Lotus FoodsÂ 25lb Oz Jasmine White Rice An Aromatic Long-Grain 100% Rice Grown By The Raun Family At ...   \n",
              "148510                                                                                                                                                                                                               Item Name: Reese Asaragus Sprs, Grlld, Marnt, 12-Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Ounce\\n   \n",
              "\n",
              "         price  \n",
              "1203     7.410  \n",
              "2121     1.320  \n",
              "2203    39.995  \n",
              "2773     4.680  \n",
              "4677    33.240  \n",
              "...        ...  \n",
              "144557     NaN  \n",
              "144712     NaN  \n",
              "144721     NaN  \n",
              "145196     NaN  \n",
              "148510     NaN  \n",
              "\n",
              "[97 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb0fd1e7-e3ab-4d54-998f-8e1d41ecd77f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>catalog_content</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1203</th>\n",
              "      <td>Item Name: Manischewitz Soup Matzo Ball Jars, 1.5 lb\\nBullet Point: Kosher for Passover and all year round\\nValue: 24.0\\nUnit: Ounce\\n</td>\n",
              "      <td>7.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>Item Name: Sweet Leaf Tea Pet Peach, 16 fl oz\\nBullet Point 1: Naturally caffeine free and All natural botanicals\\nBullet Point 2: Item Package Weight: 1.19 lb\\nBullet Point 3: Country Of Origin: United States\\nBullet Point 4: Item Package Dimension: 7.2399999926152\" L x 2.599999997348\" W x 2.59...</td>\n",
              "      <td>1.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2203</th>\n",
              "      <td>Item Name: Blue Diamond Nut Thins Almonds Honey Cinnamon Cracker Snacks, 4.25 Ounce - 12 per case.\\nBullet Point: 4.25 Ounces\\nProduct Description: Nut thins are a unique, crispy and crunchy cracker loaded with delicious and nutritious pecans. They are the only crackers made with nuts and baked ...</td>\n",
              "      <td>39.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>Item Name: Organic Cranberry Pomegrante Juice 32 Ounces (Case of 12)\\nBullet Point: 32 Ounces\\nProduct Description: An Organic Apple, Cranberry and Pomegranate Juice Blend from Concentrates with Other Ingredients.\\nValue: 12.0\\nUnit: Count\\n</td>\n",
              "      <td>4.680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4677</th>\n",
              "      <td>Item Name: Peace Clusters and Flakes Cereal, Maple Pecan, 11 Ounce (Pack of 6)\\nBullet Point 1: Whole grain oat clusters, crispy corn flakes, pecans with real maple syrup\\nBullet Point 2: We add only premium all natural grains, nuts and fruits providing you with essential whole grains, fiber and...</td>\n",
              "      <td>33.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144557</th>\n",
              "      <td>Item Name: Eden Foods Organic Apple Sauce, 25 Ounce - 12 per case.\\nBullet Point 1: Gluten Free\\nBullet Point 2: Kosher\\nValue: 12.0\\nUnit: Count\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144712</th>\n",
              "      <td>Item Name: R W Knudsen Organic Grapefruit Juice, 32 Ounce - 12 per case.\\nValue: 32.0\\nUnit: Ounce\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144721</th>\n",
              "      <td>Item Name: Taste Of Thai Noodle Qck Meal Peanut\\nValue: nan\\nUnit: None\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145196</th>\n",
              "      <td>Item Name: Organic White Jasmine Rice 25 lbs. bag\\nBullet Point: Description | Ingredients | Cooking Instructions | No Additives |Oil-Free| Allergen Free ||| |||| |\\nProduct Description: Save On Lotus FoodsÂ 25lb Oz Jasmine White Rice An Aromatic Long-Grain 100% Rice Grown By The Raun Family At ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148510</th>\n",
              "      <td>Item Name: Reese Asaragus Sprs, Grlld, Marnt, 12-Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Ounce\\n</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb0fd1e7-e3ab-4d54-998f-8e1d41ecd77f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb0fd1e7-e3ab-4d54-998f-8e1d41ecd77f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb0fd1e7-e3ab-4d54-998f-8e1d41ecd77f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-792426a4-250e-4f0b-adca-acae0195e50a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-792426a4-250e-4f0b-adca-acae0195e50a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-792426a4-250e-4f0b-adca-acae0195e50a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n--- Duplicate Image Link Analysis Complete ---\\\")\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"catalog_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"Item Name: NEAR EAST RICE MIX PILAF W MUSH&HERB, 6.3 OZ, PK- 12\\nValue: 75.6\\nUnit: Ounce\\n\",\n          \"Item Name: Field Day Beans, Og, Veg Black Refrd, 15-Ounce (Pack of 12)\\nBullet Point 1: Simmered to perfection with a hint of jalape\\u00f1o and sea salt, use these beans in your favorite Mexican recipes including taco dips, burritos, tostadas, and more\\nBullet Point 2: With a good source of protein and fiber in every serving, you won\\u2019t have to worry about having one too many Mexican nights\\nBullet Point 3: Field Day Organic Vegetarian Refried Black Beans have all the things you love about black beans, now refried\\nValue: 180.0\\nUnit: oz\\n\",\n          \"Item Name: R W Knudsen Organic Grapefruit Juice, 32 Ounce - 12 per case.\\nValue: 32.0\\nUnit: Ounce\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.80073078605171,\n        \"min\": 1.32,\n        \"max\": 109.99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          6.2,\n          1.69,\n          71.79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Duplicate Image Link Analysis Complete ---\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 2.5: EDA - INSPECTING DUPLICATE IMAGE LINKS (Your Excellent Suggestion)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"--- Inspecting for duplicate image links as per your suggestion ---\")\n",
        "\n",
        "# We will use the 'combined_df' which contains both train and test data\n",
        "# to get a complete picture of all image links in the dataset.\n",
        "\n",
        "# --- 1. Count the occurrences of each image link ---\n",
        "# .value_counts() is perfect for this. It counts each unique value.\n",
        "image_link_counts = combined_df['image_link'].value_counts()\n",
        "\n",
        "# --- 2. Filter for links that appear more than once ---\n",
        "duplicate_links = image_link_counts[image_link_counts > 1]\n",
        "\n",
        "print(f\"\\nFound {len(combined_df)} total rows.\")\n",
        "print(f\"Found {len(image_link_counts)} unique image links.\")\n",
        "print(f\"Found {len(duplicate_links)} image links that are used more than once.\")\n",
        "\n",
        "# --- 3. Display the top 10 most duplicated images ---\n",
        "if not duplicate_links.empty:\n",
        "    print(\"\\n--- Top 10 Most Duplicated Image Links ---\")\n",
        "    print(duplicate_links.head(10))\n",
        "\n",
        "    # --- 4. Let's investigate one of the top duplicates ---\n",
        "    # We'll take the most duplicated image link and see all the rows associated with it.\n",
        "    most_duplicated_link = duplicate_links.index[0]\n",
        "    print(f\"\\n--- Investigating the most duplicated link: {most_duplicated_link} ---\")\n",
        "\n",
        "    # Display all rows from the combined dataset that use this specific image link\n",
        "    # We'll show the text and the price to see if they are different.\n",
        "    display(combined_df[combined_df['image_link'] == most_duplicated_link][['catalog_content', 'price']])\n",
        "else:\n",
        "    print(\"\\nNo duplicate image links were found in the dataset.\")\n",
        "\n",
        "print(\"\\n--- Duplicate Image Link Analysis Complete ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vqBuyVlUCKZ"
      },
      "source": [
        "# **Advanced Feature Extraction**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4zd5NZ9AjQ5",
        "outputId": "fb94495d-6601-47c1-d46d-4a03a6c703f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Section 3: Defining all constants directly in the notebook.\n",
            "All constants have been defined and loaded into the notebook's memory.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 3: ADVANCED FEATURE EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "# -- 3.1: Define All Project Constants --\n",
        "# To avoid all import issues, we are defining our constants directly in this cell.\n",
        "# This makes the notebook self-contained and robust against runtime restarts.\n",
        "\n",
        "print(\"Starting Section 3: Defining all constants directly in the notebook.\")\n",
        "\n",
        "# --- 1. Column Names ---\n",
        "SAMPLE_ID_COL = 'sample_id'\n",
        "TEXT_COL = 'catalog_content'\n",
        "TARGET_COL = 'price'\n",
        "BRAND_COL = 'brand'\n",
        "WEIGHT_G_COL = 'weight_grams'\n",
        "VOLUME_ML_COL = 'volume_ml'\n",
        "PACK_COUNT_COL = 'pack_count'\n",
        "BRAND_ENCODED_COL = 'brand_encoded'\n",
        "\n",
        "\n",
        "# --- 2. Feature Extraction: Unit Lists (from EDA) ---\n",
        "WEIGHT_UNITS_G = ['g', 'gr', 'gram', 'grams', 'gramos']\n",
        "WEIGHT_UNITS_KG = ['kg', 'kgs', 'kilo', 'kilogram', 'kilograms', 'quilogramas']\n",
        "WEIGHT_UNITS_OZ = ['oz', 'ounce', 'ounces', 'onza', 'onzas']\n",
        "WEIGHT_UNITS_LB = ['lb', 'lbs', 'libra', 'libras', 'pound', 'pounds']\n",
        "WEIGHT_UNITS_MG = ['mg', 'milligram', 'milligrams']\n",
        "\n",
        "VOLUME_UNITS_ML = ['ml', 'milliliter', 'milliliters', 'mililiters']\n",
        "VOLUME_UNITS_L = ['l', 'liter', 'liters', 'litre', 'litres', 'litros']\n",
        "VOLUME_UNITS_FLOZ = ['floz', 'fl oz', 'fluid ounce']\n",
        "VOLUME_UNITS_GAL = ['gal', 'gallon', 'gallons', 'galon']\n",
        "VOLUME_UNITS_CUP = ['cup', 'cups']\n",
        "\n",
        "COUNT_UNITS = [\n",
        "    'pack', 'packs', 'pk', 'pkg', 'pck', 'count', 'ct', 'cnt', 'ea', 'each',\n",
        "    'pc', 'pcs', 'piece', 'pieces', 'dozen', 'doz', 'dz', 'roll', 'rolls',\n",
        "    'can', 'cans', 'bottle', 'bottles', 'btl', 'bag', 'bags', 'box', 'boxes', 'bx',\n",
        "    'sachet', 'sachets', 'tablet', 'tablets', 'tabs', 'capsule', 'capsules', 'caps',\n",
        "    'pods'\n",
        "]\n",
        "\n",
        "# --- 3. Feature Extraction: Conversion Maps ---\n",
        "CONVERSION_TO_G = {\n",
        "    **{unit: 1.0 for unit in WEIGHT_UNITS_G},\n",
        "    **{unit: 1000.0 for unit in WEIGHT_UNITS_KG},\n",
        "    **{unit: 28.35 for unit in WEIGHT_UNITS_OZ},\n",
        "    **{unit: 453.59 for unit in WEIGHT_UNITS_LB},\n",
        "    **{unit: 0.001 for unit in WEIGHT_UNITS_MG},\n",
        "}\n",
        "\n",
        "CONVERSION_TO_ML = {\n",
        "    **{unit: 1.0 for unit in VOLUME_UNITS_ML},\n",
        "    **{unit: 1000.0 for unit in VOLUME_UNITS_L},\n",
        "    **{unit: 29.57 for unit in VOLUME_UNITS_FLOZ},\n",
        "    **{unit: 3785.41 for unit in VOLUME_UNITS_GAL},\n",
        "    **{unit: 236.59 for unit in VOLUME_UNITS_CUP},\n",
        "}\n",
        "\n",
        "# --- 4. Model Training Constants ---\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 5\n",
        "LGB_PARAMS = {\n",
        "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 2000,\n",
        "    'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'num_leaves': 31,\n",
        "    'verbose': -1, 'n_jobs': -1, 'seed': RANDOM_STATE, 'boosting_type': 'gbdt',\n",
        "}\n",
        "TFIDF_MAX_FEATURES = 5000\n",
        "TFIDF_NGRAM_RANGE = (1, 2)\n",
        "\n",
        "print(\"All constants have been defined and loaded into the notebook's memory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHvGI78lAjN-",
        "outputId": "e43281c5-128a-4eb9-e7b8-ccc5945962a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up the main feature extraction function...\n",
            "Initialized new columns: brand, weight_grams, volume_ml, pack_count\n",
            "Initialized new columns: brand, weight_grams, volume_ml, pack_count\n",
            "\n",
            "Initial feature dataframes created.\n",
            "First 5 rows of the new training dataframe with empty features:\n",
            "   sample_id    brand  weight_grams  volume_ml  pack_count\n",
            "0      33127  unknown           NaN        NaN           1\n",
            "1     198967  unknown           NaN        NaN           1\n",
            "2     261251  unknown           NaN        NaN           1\n",
            "3      55858  unknown           NaN        NaN           1\n",
            "4     292686  unknown           NaN        NaN           1\n"
          ]
        }
      ],
      "source": [
        "# -- 3.2: Setup Main Extraction Function --\n",
        "\n",
        "print(\"Setting up the main feature extraction function...\")\n",
        "\n",
        "def extract_features(df):\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the extraction of all new features.\n",
        "    We will add the logic for each feature to this function step-by-step.\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Initialize New Columns using the constants defined in the previous cell\n",
        "    df_copy[BRAND_COL] = 'unknown'\n",
        "    df_copy[WEIGHT_G_COL] = np.nan\n",
        "    df_copy[VOLUME_ML_COL] = np.nan\n",
        "    df_copy[PACK_COUNT_COL] = 1 # Default to 1\n",
        "\n",
        "    print(f\"Initialized new columns: {BRAND_COL}, {WEIGHT_G_COL}, {VOLUME_ML_COL}, {PACK_COUNT_COL}\")\n",
        "\n",
        "    # We will add the real extraction logic here in subsequent steps.\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "# --- Apply the initial function to our dataframes ---\n",
        "train_featured_df = extract_features(train_df)\n",
        "test_featured_df = extract_features(test_df)\n",
        "\n",
        "print(\"\\nInitial feature dataframes created.\")\n",
        "print(\"First 5 rows of the new training dataframe with empty features:\")\n",
        "print(train_featured_df[[SAMPLE_ID_COL, BRAND_COL, WEIGHT_G_COL, VOLUME_ML_COL, PACK_COUNT_COL]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jefG3VHfctU",
        "outputId": "9fb1b82a-19c3-49bf-973b-9e8cd789e99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correcting the feature extraction logic to properly capture Volume...\n",
            "\n",
            "Feature extraction re-run with CORRECTED Volume logic.\n",
            "\n",
            "--- FINAL VERIFICATION ---\n",
            "Top 15 most common brands found:\n",
            "brand\n",
            "To            947\n",
            "Mccormick     637\n",
            "Goya          445\n",
            "Rani          425\n",
            "Frontier      370\n",
            "La            344\n",
            "Betty         328\n",
            "Starbucks     308\n",
            "Badia         286\n",
            "Bob'S         277\n",
            "Amoretti      277\n",
            "Crystal       256\n",
            "Campbell'S    253\n",
            "Fresh         251\n",
            "Kraft         244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Example of all new features extracted:\n",
            "   sample_id     brand  weight_grams  volume_ml  pack_count\n",
            "0      33127        La      340.2000        NaN         6.0\n",
            "1     198967   Salerno      226.8000        NaN         4.0\n",
            "2     261251      Bear       53.8650        NaN         6.0\n",
            "3      55858   Judee’S      318.9375        NaN         1.0\n",
            "4     292686     Kedem      360.0450        NaN         1.0\n",
            "5       9259  Member'S      177.1875        NaN         1.0\n",
            "6     191846      Goya      850.5000        NaN         6.0\n",
            "7     222007    Vineco           NaN        NaN         1.0\n",
            "8      37614   Natures      907.2000        NaN         1.0\n",
            "9     238044      Mrs.      255.1500        NaN         4.0\n",
            "\n",
            "Number of non-null values in 'volume_ml': 5544\n"
          ]
        }
      ],
      "source": [
        "# -- 3.3: All Feature Extraction (V8 - Fixing Volume Extraction) --\n",
        "\n",
        "print(\"Correcting the feature extraction logic to properly capture Volume...\")\n",
        "\n",
        "# Using the same NON_BRAND_WORDS list from our last successful attempt\n",
        "NON_BRAND_WORDS = [\n",
        "    'The', 'A', 'An', 'Organic', 'Gluten-Free', 'Natural', 'Pure', 'Food', 'Gourmet', 'Simply',\n",
        "    'And', 'For', 'With', 'Pack', 'To', 'Of', 'In', 'From', 'By', 'On', 'At', 'Is', 'It',\n",
        "    'Red', 'Blue', 'Green', 'Black', 'White', 'Spice', 'Spices', 'And'\n",
        "]\n",
        "\n",
        "def extract_features(df):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # --- Initialize Columns ---\n",
        "    df_copy[BRAND_COL] = 'unknown'\n",
        "    df_copy[WEIGHT_G_COL] = np.nan\n",
        "    df_copy[VOLUME_ML_COL] = np.nan\n",
        "    df_copy[PACK_COUNT_COL] = 1\n",
        "\n",
        "    # --- Isolate the 'Item Name' line ---\n",
        "    item_name_line = df_copy[TEXT_COL].str.extract(r'Item Name:\\s*(.*)', flags=re.IGNORECASE).iloc[:, 0].fillna('')\n",
        "\n",
        "    # --- 1. BRAND EXTRACTION ---\n",
        "    def get_brand(name):\n",
        "        if not isinstance(name, str) or not name: return 'unknown'\n",
        "        words = name.split()\n",
        "        first_word = words[0].title().replace(',', '')\n",
        "        if first_word in NON_BRAND_WORDS:\n",
        "            if len(words) > 1:\n",
        "                second_word = words[1].title().replace(',', '')\n",
        "                return second_word\n",
        "            else:\n",
        "                return 'unknown'\n",
        "        return first_word\n",
        "    df_copy[BRAND_COL] = item_name_line.apply(get_brand)\n",
        "\n",
        "    # --- 2. PACK, WEIGHT, VOLUME EXTRACTION (CORRECTED LOGIC) ---\n",
        "    # Pack Count\n",
        "    pack_pattern = re.compile(r'(?:pack of|per case|count of|\\()\\s*(\\d+)', flags=re.IGNORECASE)\n",
        "    extracted_packs = item_name_line.str.extract(pack_pattern, expand=False).astype(float)\n",
        "    df_copy[PACK_COUNT_COL] = extracted_packs.fillna(df_copy[PACK_COUNT_COL])\n",
        "\n",
        "    # --- ROBUST WEIGHT & VOLUME EXTRACTION ---\n",
        "    # We will process them separately and more carefully.\n",
        "\n",
        "    # Weight Extraction\n",
        "    all_weight_units = '|'.join(CONVERSION_TO_G.keys())\n",
        "    weight_pattern = re.compile(r'(\\d+\\.?\\d*)\\s*(' + all_weight_units + r')\\b', flags=re.IGNORECASE)\n",
        "    weight_matches = item_name_line.str.extract(weight_pattern)\n",
        "\n",
        "    # Check if the matches DataFrame is not empty and has the expected columns\n",
        "    if not weight_matches.empty and weight_matches.shape[1] == 2:\n",
        "        value = pd.to_numeric(weight_matches[0], errors='coerce')\n",
        "        unit = weight_matches[1].str.lower()\n",
        "        conversion = unit.map(CONVERSION_TO_G)\n",
        "        # Calculate weights only for rows where a match was found\n",
        "        calculated_weights = value * conversion\n",
        "        # Use the 'where' condition to fill NaNs\n",
        "        df_copy[WEIGHT_G_COL] = df_copy[WEIGHT_G_COL].where(calculated_weights.isna(), calculated_weights)\n",
        "\n",
        "    # Volume Extraction\n",
        "    all_volume_units = '|'.join(CONVERSION_TO_ML.keys())\n",
        "    volume_pattern = re.compile(r'(\\d+\\.?\\d*)\\s*(' + all_volume_units + r')\\b', flags=re.IGNORECASE)\n",
        "    volume_matches = item_name_line.str.extract(volume_pattern)\n",
        "\n",
        "    if not volume_matches.empty and volume_matches.shape[1] == 2:\n",
        "        value = pd.to_numeric(volume_matches[0], errors='coerce')\n",
        "        unit = volume_matches[1].str.lower()\n",
        "        conversion = unit.map(CONVERSION_TO_ML)\n",
        "        calculated_volumes = value * conversion\n",
        "        df_copy[VOLUME_ML_COL] = df_copy[VOLUME_ML_COL].where(calculated_volumes.isna(), calculated_volumes)\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "# --- Re-run the extraction ---\n",
        "train_featured_df = extract_features(train_df)\n",
        "test_featured_df = extract_features(test_df)\n",
        "\n",
        "print(\"\\nFeature extraction re-run with CORRECTED Volume logic.\")\n",
        "\n",
        "# --- Verification ---\n",
        "print(\"\\n--- FINAL VERIFICATION ---\")\n",
        "print(\"Top 15 most common brands found:\")\n",
        "print(train_featured_df[BRAND_COL].value_counts().head(15))\n",
        "\n",
        "print(\"\\nExample of all new features extracted:\")\n",
        "print(train_featured_df[[SAMPLE_ID_COL, BRAND_COL, WEIGHT_G_COL, VOLUME_ML_COL, PACK_COUNT_COL]].head(10))\n",
        "\n",
        "# --- NEW: Check the status of the volume column ---\n",
        "print(f\"\\nNumber of non-null values in '{VOLUME_ML_COL}': {train_featured_df[VOLUME_ML_COL].notna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0lZC4wohydc"
      },
      "source": [
        "# **Data Preparation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb6XRbnGfcmj",
        "outputId": "030921d0-7bda-41a0-cead-9397db47bc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Section 4 with a robust Preprocessing Pipeline strategy.\n",
            "Cleaned rare brands. Number of unique brands is now: 3905\n",
            "\n",
            "Defined feature groups for the pipeline:\n",
            "Text Feature: catalog_content\n",
            "Numeric Features: ['weight_grams', 'volume_ml', 'pack_count']\n",
            "Categorical Feature: brand\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 4: DATA PREPARATION WITH A PREPROCESSING PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "# -- 4.1: Define Feature Groups --\n",
        "# We are switching to a scikit-learn Pipeline to handle preprocessing more robustly\n",
        "# and prevent any potential data leakage during cross-validation.\n",
        "\n",
        "print(\"Starting Section 4 with a robust Preprocessing Pipeline strategy.\")\n",
        "\n",
        "# First, let's clean up the rare brands as we discussed before.\n",
        "# This is a data cleaning step done before the pipeline.\n",
        "brand_counts = train_featured_df[BRAND_COL].value_counts()\n",
        "rare_brands = brand_counts[brand_counts < 3].index\n",
        "train_featured_df.loc[train_featured_df[BRAND_COL].isin(rare_brands), BRAND_COL] = 'unknown'\n",
        "test_featured_df.loc[test_featured_df[BRAND_COL].isin(rare_brands), BRAND_COL] = 'unknown'\n",
        "print(f\"Cleaned rare brands. Number of unique brands is now: {train_featured_df[BRAND_COL].nunique()}\")\n",
        "\n",
        "\n",
        "# Define the groups of columns for our ColumnTransformer.\n",
        "# Note: We use the original train_df for the text column to ensure it's clean.\n",
        "# The other features come from our 'train_featured_df'.\n",
        "\n",
        "# 1. Text feature\n",
        "text_feature = TEXT_COL\n",
        "\n",
        "# 2. Numerical features\n",
        "numeric_features = [WEIGHT_G_COL, VOLUME_ML_COL, PACK_COUNT_COL]\n",
        "\n",
        "# 3. Categorical feature\n",
        "categorical_feature = BRAND_COL\n",
        "\n",
        "print(\"\\nDefined feature groups for the pipeline:\")\n",
        "print(f\"Text Feature: {text_feature}\")\n",
        "print(f\"Numeric Features: {numeric_features}\")\n",
        "print(f\"Categorical Feature: {categorical_feature}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClOOZt6qfcjq",
        "outputId": "d713f2d5-0187-49bb-81c0-d0d869ae5d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Section 4: Building the preprocessing pipeline.\n",
            "Cleaned rare brands. Number of unique brands is now: 3905\n",
            "\n",
            "Defined feature groups for the pipeline:\n",
            "Text Feature: catalog_content\n",
            "Numeric Features: ['weight_grams', 'volume_ml', 'pack_count']\n",
            "Categorical Feature: brand\n",
            "\n",
            "Building the ColumnTransformer...\n",
            "\n",
            "Preprocessing pipeline ('preprocessor') built successfully.\n",
            "\n",
            "--- Section 4 Complete ---\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 4: DATA PREPARATION WITH A PREPROCESSING PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "# --- 4.1: Import Libraries and Define Feature Groups ---\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "print(\"Starting Section 4: Building the preprocessing pipeline.\")\n",
        "\n",
        "# Define the groups of columns for our ColumnTransformer.\n",
        "text_feature = TEXT_COL\n",
        "numeric_features = [WEIGHT_G_COL, VOLUME_ML_COL, PACK_COUNT_COL]\n",
        "categorical_feature = BRAND_COL\n",
        "\n",
        "# Clean rare brands before defining the pipeline.\n",
        "# This is an important data cleaning step.\n",
        "brand_counts = train_featured_df[BRAND_COL].value_counts()\n",
        "rare_brands = brand_counts[brand_counts < 3].index\n",
        "train_featured_df.loc[train_featured_df[BRAND_COL].isin(rare_brands), BRAND_COL] = 'unknown'\n",
        "test_featured_df.loc[test_featured_df[BRAND_COL].isin(rare_brands), BRAND_COL] = 'unknown'\n",
        "print(f\"Cleaned rare brands. Number of unique brands is now: {train_featured_df[BRAND_COL].nunique()}\")\n",
        "\n",
        "print(\"\\nDefined feature groups for the pipeline:\")\n",
        "print(f\"Text Feature: {text_feature}\")\n",
        "print(f\"Numeric Features: {numeric_features}\")\n",
        "print(f\"Categorical Feature: {categorical_feature}\")\n",
        "\n",
        "# --- 4.2: Build the Preprocessing Pipeline ---\n",
        "print(\"\\nBuilding the ColumnTransformer...\")\n",
        "\n",
        "# Define the transformer for numeric features (impute missing values)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])\n",
        "\n",
        "# Define the transformer for the categorical 'brand' feature (one-hot encode)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
        "])\n",
        "\n",
        "# Define the transformer for the text feature (TF-IDF)\n",
        "text_transformer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, stop_words='english', ngram_range=TFIDF_NGRAM_RANGE)\n",
        "\n",
        "# Create the master preprocessor object that applies each transformer to the correct columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, [categorical_feature]),\n",
        "        ('text', text_transformer, text_feature)\n",
        "    ],\n",
        "    remainder='drop' # Drop any columns that we haven't specified\n",
        ")\n",
        "\n",
        "print(\"\\nPreprocessing pipeline ('preprocessor') built successfully.\")\n",
        "print(\"\\n--- Section 4 Complete ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMr1ytzujx7H"
      },
      "source": [
        "# **Model Training and Evaluation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPKuFwyA6wLR",
        "outputId": "5478abd1-5376-4208-a2bc-0312357bf857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Implementing your data cleaning strategy: Removing rows with placeholder images. ---\n",
            "Identified 5 images as placeholders (appearing > 10 times).\n",
            "The top 5 are:\n",
            "['https://m.media-amazon.com/images/I/51m1gdQJW2L.jpg', 'https://m.media-amazon.com/images/I/71LRdXdqc0L.jpg', 'https://m.media-amazon.com/images/I/21mMXLWiDOL.jpg', 'https://m.media-amazon.com/images/I/61md5v6UPNL.jpg', 'https://m.media-amazon.com/images/I/71FMi9tO3HL.jpg']\n",
            "\n",
            "Original training data had 75000 rows.\n",
            "Removed 109 rows that used placeholder images.\n",
            "Cleaned training data now has 74891 rows.\n",
            "\n",
            "--- Data Cleaning Complete ---\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 4.4: DATA CLEANING (YOUR STRATEGY: REMOVE PLACEHOLDER IMAGES)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"--- Implementing your data cleaning strategy: Removing rows with placeholder images. ---\")\n",
        "\n",
        "# --- 1. Identify the placeholder images ---\n",
        "# Based on our EDA, we'll define a \"placeholder\" as any image that appears more than 10 times.\n",
        "# This is a reasonable threshold to catch the most generic images.\n",
        "image_link_counts = train_featured_df['image_link'].value_counts()\n",
        "placeholder_links = image_link_counts[image_link_counts > 10].index.tolist()\n",
        "\n",
        "print(f\"Identified {len(placeholder_links)} images as placeholders (appearing > 10 times).\")\n",
        "print(\"The top 5 are:\")\n",
        "print(placeholder_links[:5])\n",
        "\n",
        "# --- 2. Remove these rows from the training data ---\n",
        "# We will only clean the training data. We should not remove rows from the test set.\n",
        "original_row_count = len(train_featured_df)\n",
        "train_df_cleaned = train_featured_df[~train_featured_df['image_link'].isin(placeholder_links)]\n",
        "cleaned_row_count = len(train_df_cleaned)\n",
        "\n",
        "print(f\"\\nOriginal training data had {original_row_count} rows.\")\n",
        "print(f\"Removed {original_row_count - cleaned_row_count} rows that used placeholder images.\")\n",
        "print(f\"Cleaned training data now has {cleaned_row_count} rows.\")\n",
        "\n",
        "print(\"\\n--- Data Cleaning Complete ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CatBoost**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "K-Q8hrCZfOfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VaNNLMfgpjD",
        "outputId": "af1da2f6-4a53-4cd2-fe0b-dfc34b180b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm0oP-jq6wBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc07b4d-1979-460e-b159-8eb8d6e640af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Definitive CatBoost Pipeline Run (GPU-Enabled) ---\n",
            "Custom CatBoostWrapper for scikit-learn pipeline created successfully.\n",
            "Using all 74891 rows from the cleaned dataset.\n",
            "Final training rows after ensuring target is numeric: 74891\n",
            "\n",
            "--- Fitting the final CatBoost pipeline on all available clean data (GPU)... ---\n",
            "0:\tlearn: 0.9389526\ttotal: 402ms\tremaining: 26m 47s\n",
            "500:\tlearn: 0.7385476\ttotal: 1m 36s\tremaining: 11m 10s\n",
            "1000:\tlearn: 0.7097317\ttotal: 3m 7s\tremaining: 9m 21s\n",
            "1500:\tlearn: 0.6918770\ttotal: 4m 37s\tremaining: 7m 41s\n",
            "2000:\tlearn: 0.6797215\ttotal: 6m 6s\tremaining: 6m 6s\n",
            "2500:\tlearn: 0.6698335\ttotal: 7m 34s\tremaining: 4m 32s\n",
            "3000:\tlearn: 0.6616345\ttotal: 9m 2s\tremaining: 3m\n",
            "3500:\tlearn: 0.6542530\ttotal: 10m 30s\tremaining: 1m 29s\n",
            "3999:\tlearn: 0.6476591\ttotal: 11m 58s\tremaining: 0us\n",
            "\n",
            "--- FITTING COMPLETE ---\n",
            "Total CatBoost GPU training time: 18.17 minutes.\n",
            "\n",
            "--- Section 5 Complete: Definitive CatBoost model successfully trained. ---\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION 5: CATBOOST PIPELINE MODEL TRAINING (GPU-ENABLED)\n",
        "# =============================================================================\n",
        "# This section creates a definitive, GPU-enabled CatBoost model that\n",
        "# integrates perfectly with the scikit-learn preprocessing pipeline.\n",
        "\n",
        "print(\"--- Starting Definitive CatBoost Pipeline Run (GPU-Enabled) ---\")\n",
        "\n",
        "# --- 1. Import necessary libraries ---\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from catboost import CatBoostRegressor\n",
        "import time\n",
        "\n",
        "# --- 2. Create a Custom CatBoost Wrapper for Pipeline Compatibility ---\n",
        "# This is the key to solving the previous errors. This wrapper converts the\n",
        "# sparse data from the preprocessor into a dense format that CatBoost requires.\n",
        "class CatBoostWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.model = CatBoostRegressor(**kwargs)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert sparse matrix to dense numpy array before fitting\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Convert sparse matrix to dense numpy array before predicting\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        return self.model.predict(X)\n",
        "\n",
        "print(\"Custom CatBoostWrapper for scikit-learn pipeline created successfully.\")\n",
        "\n",
        "# --- 3. Use the FULL cleaned DataFrame ---\n",
        "# This code assumes 'train_df_cleaned' was created in Section 4.\n",
        "print(f\"Using all {len(train_df_cleaned)} rows from the cleaned dataset.\")\n",
        "\n",
        "# --- 4. Define the final CatBoost model pipeline with GPU enabled ---\n",
        "# This pipeline is identical in structure to your LightGBM pipeline.\n",
        "model_pipeline_catboost = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', CatBoostWrapper(\n",
        "        task_type='GPU',      # Enable GPU\n",
        "        devices='0',          # Use the first available GPU\n",
        "        iterations=4000,      # Aggressive tuning\n",
        "        learning_rate=0.015,\n",
        "        depth=9,\n",
        "        l2_leaf_reg=5,\n",
        "        loss_function='RMSE',\n",
        "        eval_metric='RMSE',\n",
        "        random_seed=RANDOM_STATE,\n",
        "        verbose=500,          # Print progress\n",
        "        # No 'cat_features' needed here, as they are already one-hot encoded by the pipeline\n",
        "    ))\n",
        "])\n",
        "\n",
        "# --- 5. Define the Full, Cleaned Data for Fitting ---\n",
        "# Clean the target column to ensure it's numeric, removing rows if necessary.\n",
        "train_df_cleaned[TARGET_COL] = pd.to_numeric(train_df_cleaned[TARGET_COL], errors='coerce')\n",
        "train_df_cleaned.dropna(subset=[TARGET_COL], inplace=True)\n",
        "print(f\"Final training rows after ensuring target is numeric: {len(train_df_cleaned)}\")\n",
        "\n",
        "X_train_definitive = train_df_cleaned[[text_feature] + numeric_features + [categorical_feature]]\n",
        "y_train_definitive = np.log1p(train_df_cleaned[TARGET_COL]) # Log-transform the target\n",
        "\n",
        "# --- 6. Fit the CatBoost Pipeline on the Full, Cleaned Dataset ---\n",
        "print(\"\\n--- Fitting the final CatBoost pipeline on all available clean data (GPU)... ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "model_pipeline_catboost.fit(X_train_definitive, y_train_definitive)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- FITTING COMPLETE ---\")\n",
        "print(f\"Total CatBoost GPU training time: {(end_time - start_time)/60:.2f} minutes.\")\n",
        "print(\"\\n--- Section 5 Complete: Definitive CatBoost model successfully trained. ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGkLo6or6v-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202feac1-2c49-4e82-f5e1-7b4db01ea7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Final CatBoost Submission File ---\n",
            "Making predictions on the test set...\n",
            "Predictions generated successfully.\n",
            "\n",
            "Submission file 'submission_catboost_pipeline_gpu.csv' created successfully.\n",
            "This is your definitive CatBoost submission.\n"
          ]
        }
      ],
      "source": [
        "#  =============================================================================\n",
        "# SECTION 6: GENERATE FINAL CATBOOST SUBMISSION\n",
        "# =============================================================================\n",
        "# This cell uses the 'model_pipeline_catboost' object created in Section 5.\n",
        "\n",
        "print(\"\\n--- Generating Final CatBoost Submission File ---\")\n",
        "\n",
        "# Define the test data for prediction\n",
        "X_test_full = test_featured_df[[text_feature] + numeric_features + [categorical_feature]]\n",
        "\n",
        "# Make predictions on the test set\n",
        "print(\"Making predictions on the test set...\")\n",
        "test_predictions_log = model_pipeline_catboost.predict(X_test_full)\n",
        "test_predictions = np.expm1(test_predictions_log) # Inverse the log-transform\n",
        "print(\"Predictions generated successfully.\")\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df_catboost = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': test_predictions\n",
        "})\n",
        "submission_df_catboost['price'] = submission_df_catboost['price'].clip(lower=0)\n",
        "\n",
        "# Save the final submission file\n",
        "submission_df_catboost.to_csv(\"submission_catboost_pipeline_gpu.csv\", index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission_catboost_pipeline_gpu.csv' created successfully.\")\n",
        "print(\"This is your definitive CatBoost submission.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Iq8euz1vnS8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 5: MEMORY-EFFICIENT PYTORCH MLP (CRASH FIX)\n",
        "# =============================================================================\n",
        "# This version uses a custom PyTorch Dataset to handle the large, sparse\n",
        "# feature matrix efficiently, preventing the RAM overflow that causes crashes.\n",
        "\n",
        "print(\"--- Starting Memory-Efficient PyTorch MLP Run ---\")\n",
        "\n",
        "# --- 1. Import libraries ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "print(\"Libraries imported successfully.\")\n",
        "\n",
        "# --- 2. Verify GPU ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 3. Preprocess data (but keep it sparse!) ---\n",
        "print(\"Preparing data with the scikit-learn pipeline...\")\n",
        "transform_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler(with_mean=False))\n",
        "])\n",
        "\n",
        "train_df_cleaned[TARGET_COL] = pd.to_numeric(train_df_cleaned[TARGET_COL], errors='coerce')\n",
        "train_df_cleaned.dropna(subset=[TARGET_COL], inplace=True)\n",
        "print(f\"Final training rows: {len(train_df_cleaned)}\")\n",
        "\n",
        "X_train_data = train_df_cleaned[[text_feature] + numeric_features + [categorical_feature]]\n",
        "y_train_data = np.log1p(train_df_cleaned[TARGET_COL])\n",
        "\n",
        "# IMPORTANT: We fit the pipeline and transform, but DO NOT call .toarray()\n",
        "X_train_sparse = transform_pipeline.fit_transform(X_train_data)\n",
        "y_train_numpy = y_train_data.values\n",
        "\n",
        "X_test_data = test_featured_df[[text_feature] + numeric_features + [categorical_feature]]\n",
        "X_test_sparse = transform_pipeline.transform(X_test_data)\n",
        "\n",
        "print(f\"Data transformed into a sparse matrix of shape: {X_train_sparse.shape}\")\n",
        "\n",
        "# --- 4. Create a Custom Memory-Efficient PyTorch Dataset ---\n",
        "class SparseDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # This is the key: .toarray() is only called for ONE row at a time!\n",
        "        return torch.tensor(self.X[idx].toarray().flatten(), dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "\n",
        "train_dataset = SparseDataset(X_train_sparse, y_train_numpy)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# --- 5. Define MLP Model and SMAPE Loss (same as before) ---\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(nn.Linear(input_size, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.3), nn.Linear(128, 1))\n",
        "    def forward(self, x): return self.layers(x)\n",
        "\n",
        "class SmapeLoss(nn.Module):\n",
        "    def __init__(self, epsilon=1e-8):\n",
        "        super().__init__(); self.epsilon = epsilon\n",
        "    def forward(self, y_pred_log, y_true_log):\n",
        "        y_pred = torch.expm1(y_pred_log); y_true = torch.expm1(y_true_log)\n",
        "        numerator = torch.abs(y_pred - y_true)\n",
        "        denominator = (torch.abs(y_true) + torch.abs(y_pred)) / 2\n",
        "        return torch.mean(numerator / (denominator + self.epsilon)) * 100\n",
        "\n",
        "# --- 6. Initialize and Train ---\n",
        "input_size = X_train_sparse.shape[1]\n",
        "model = MLP(input_size).to(device)\n",
        "criterion = SmapeLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\n--- Fitting the PyTorch MLP model (Memory-Efficient)... ---\")\n",
        "start_time = time.time()\n",
        "num_epochs = 60\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for features, labels in train_loader:\n",
        "        features = features.to(device); labels = labels.to(device).view(-1, 1)\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average SMAPE Loss: {epoch_loss/len(train_loader):.4f}')\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- FITTING COMPLETE ---\")\n",
        "print(f\"Total training time: {(end_time - start_time)/60:.2f} minutes.\")\n"
      ],
      "metadata": {
        "id": "kf6-AwH5eZGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b14091a-c2c6-4751-a425-85a24a76faa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Memory-Efficient PyTorch MLP Run ---\n",
            "Libraries imported successfully.\n",
            "Using device: cuda\n",
            "Preparing data with the scikit-learn pipeline...\n",
            "Final training rows: 74891\n",
            "Data transformed into a sparse matrix of shape: (74891, 8908)\n",
            "\n",
            "--- Fitting the PyTorch MLP model (Memory-Efficient)... ---\n",
            "Epoch [1/60], Average SMAPE Loss: 71.7077\n",
            "Epoch [2/60], Average SMAPE Loss: 60.7538\n",
            "Epoch [3/60], Average SMAPE Loss: 57.0746\n",
            "Epoch [4/60], Average SMAPE Loss: 54.5282\n",
            "Epoch [5/60], Average SMAPE Loss: 52.0985\n",
            "Epoch [6/60], Average SMAPE Loss: 49.6944\n",
            "Epoch [7/60], Average SMAPE Loss: 48.1245\n",
            "Epoch [8/60], Average SMAPE Loss: 46.3193\n",
            "Epoch [9/60], Average SMAPE Loss: 45.2769\n",
            "Epoch [10/60], Average SMAPE Loss: 43.7166\n",
            "Epoch [11/60], Average SMAPE Loss: 42.1652\n",
            "Epoch [12/60], Average SMAPE Loss: 41.5176\n",
            "Epoch [13/60], Average SMAPE Loss: 40.5393\n",
            "Epoch [14/60], Average SMAPE Loss: 39.4096\n",
            "Epoch [15/60], Average SMAPE Loss: 38.5153\n",
            "Epoch [16/60], Average SMAPE Loss: 37.9257\n",
            "Epoch [17/60], Average SMAPE Loss: 36.8404\n",
            "Epoch [18/60], Average SMAPE Loss: 36.3141\n",
            "Epoch [19/60], Average SMAPE Loss: 35.6556\n",
            "Epoch [20/60], Average SMAPE Loss: 35.3347\n",
            "Epoch [21/60], Average SMAPE Loss: 34.7635\n",
            "Epoch [22/60], Average SMAPE Loss: 34.2018\n",
            "Epoch [23/60], Average SMAPE Loss: 33.5871\n",
            "Epoch [24/60], Average SMAPE Loss: 33.2329\n",
            "Epoch [25/60], Average SMAPE Loss: 32.9273\n",
            "Epoch [26/60], Average SMAPE Loss: 32.3222\n",
            "Epoch [27/60], Average SMAPE Loss: 32.1926\n",
            "Epoch [28/60], Average SMAPE Loss: 31.9640\n",
            "Epoch [29/60], Average SMAPE Loss: 31.3515\n",
            "Epoch [30/60], Average SMAPE Loss: 30.8911\n",
            "Epoch [31/60], Average SMAPE Loss: 30.7339\n",
            "Epoch [32/60], Average SMAPE Loss: 30.5589\n",
            "Epoch [33/60], Average SMAPE Loss: 30.1009\n",
            "Epoch [34/60], Average SMAPE Loss: 29.7319\n",
            "Epoch [35/60], Average SMAPE Loss: 29.3928\n",
            "Epoch [36/60], Average SMAPE Loss: 29.2136\n",
            "Epoch [37/60], Average SMAPE Loss: 28.7140\n",
            "Epoch [38/60], Average SMAPE Loss: 28.9666\n",
            "Epoch [39/60], Average SMAPE Loss: 28.3096\n",
            "Epoch [40/60], Average SMAPE Loss: 28.0488\n",
            "Epoch [41/60], Average SMAPE Loss: 27.8911\n",
            "Epoch [42/60], Average SMAPE Loss: 27.8882\n",
            "Epoch [43/60], Average SMAPE Loss: 27.4579\n",
            "Epoch [44/60], Average SMAPE Loss: 27.5113\n",
            "Epoch [45/60], Average SMAPE Loss: 27.0639\n",
            "Epoch [46/60], Average SMAPE Loss: 26.9377\n",
            "Epoch [47/60], Average SMAPE Loss: 26.7587\n",
            "Epoch [48/60], Average SMAPE Loss: 26.5163\n",
            "Epoch [49/60], Average SMAPE Loss: 26.6345\n",
            "Epoch [50/60], Average SMAPE Loss: 26.3393\n",
            "Epoch [51/60], Average SMAPE Loss: 26.0644\n",
            "Epoch [52/60], Average SMAPE Loss: 25.9554\n",
            "Epoch [53/60], Average SMAPE Loss: 25.9074\n",
            "Epoch [54/60], Average SMAPE Loss: 25.6900\n",
            "Epoch [55/60], Average SMAPE Loss: 25.5980\n",
            "Epoch [56/60], Average SMAPE Loss: 25.6431\n",
            "Epoch [57/60], Average SMAPE Loss: 25.1494\n",
            "Epoch [58/60], Average SMAPE Loss: 25.1707\n",
            "Epoch [59/60], Average SMAPE Loss: 24.8978\n",
            "Epoch [60/60], Average SMAPE Loss: 24.9887\n",
            "\n",
            "--- FITTING COMPLETE ---\n",
            "Total training time: 10.33 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine Tuning**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zBb_OPoNL-yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 6: FINE-TUNING THE MLP MODEL FOR A BETTER SCORE\n",
        "# =============================================================================\n",
        "# We take our already-trained model and fine-tune it with a lower learning\n",
        "# rate to try and squeeze out a bit more performance.\n",
        "\n",
        "print(\"--- Starting Fine-Tuning of the Trained MLP Model ---\")\n",
        "\n",
        "# --- 1. Lower the Learning Rate ---\n",
        "# We access the optimizer and reduce the learning rate by a factor of 10.\n",
        "new_lr = 0.0001\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = new_lr\n",
        "\n",
        "print(f\"Optimizer's learning rate has been reduced to: {new_lr}\")\n",
        "\n",
        "# --- 2. Fine-Tune for a Few More Epochs ---\n",
        "print(\"\\n--- Fine-tuning for 30 more epochs... ---\")\n",
        "fine_tune_epochs = 30\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(fine_tune_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for features, labels in train_loader:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device).view(-1, 1)\n",
        "\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f'Fine-Tuning Epoch [{epoch+1}/{fine_tune_epochs}], Average SMAPE Loss: {epoch_loss/len(train_loader):.4f}')\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- FINE-TUNING COMPLETE ---\")\n",
        "print(f\"Total fine-tuning time: {(end_time - start_time)/60:.2f} minutes.\")\n",
        "\n",
        "# --- 3. Generate the New Submission File ---\n",
        "# Use the same \"bulletproof\" submission code as before.\n",
        "print(\"\\n--- Generating Final Fine-Tuned Submission File ---\")\n",
        "# (The rest of the submission code is the same)\n",
        "\n",
        "model.eval()\n",
        "final_predictions = []\n",
        "batch_size = 512\n",
        "with torch.no_grad():\n",
        "    for i in range(0, X_test_sparse.shape[0], batch_size):\n",
        "        X_batch_sparse = X_test_sparse[i:i + batch_size]\n",
        "        X_batch_dense = torch.tensor(X_batch_sparse.toarray(), dtype=torch.float32).to(device)\n",
        "        outputs = model(X_batch_dense)\n",
        "        final_predictions.append(outputs.cpu())\n",
        "\n",
        "test_predictions_log = torch.cat(final_predictions).numpy()\n",
        "final_predictions = np.expm1(test_predictions_log)\n",
        "\n",
        "if np.isnan(final_predictions).any() or np.isinf(final_predictions).any():\n",
        "    median_pred = np.nanmedian(final_predictions)\n",
        "    final_predictions = np.nan_to_num(final_predictions, nan=median_pred, posinf=median_pred, neginf=median_pred)\n",
        "\n",
        "final_predictions = final_predictions.clip(min=0)\n",
        "\n",
        "submission_df_mlp = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': final_predictions.flatten()\n",
        "})\n",
        "\n",
        "submission_df_mlp.to_csv(\"submission_mlp_finetuned.csv\", index=False)\n",
        "print(\"\\nSubmission file 'submission_mlp_finetuned.csv' created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYpE5oLYkLh0",
        "outputId": "1f6ebe3b-bf27-45f4-d3cc-fb895e519f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Fine-Tuning of the Trained MLP Model ---\n",
            "Optimizer's learning rate has been reduced to: 0.0001\n",
            "\n",
            "--- Fine-tuning for 30 more epochs... ---\n",
            "Fine-Tuning Epoch [1/30], Average SMAPE Loss: 23.4028\n",
            "Fine-Tuning Epoch [2/30], Average SMAPE Loss: 22.8269\n",
            "Fine-Tuning Epoch [3/30], Average SMAPE Loss: 22.3797\n",
            "Fine-Tuning Epoch [4/30], Average SMAPE Loss: 22.0501\n",
            "Fine-Tuning Epoch [5/30], Average SMAPE Loss: 21.8376\n",
            "Fine-Tuning Epoch [6/30], Average SMAPE Loss: 21.5299\n",
            "Fine-Tuning Epoch [7/30], Average SMAPE Loss: 21.3155\n",
            "Fine-Tuning Epoch [8/30], Average SMAPE Loss: 21.1088\n",
            "Fine-Tuning Epoch [9/30], Average SMAPE Loss: 21.0551\n",
            "Fine-Tuning Epoch [10/30], Average SMAPE Loss: 20.9033\n",
            "Fine-Tuning Epoch [11/30], Average SMAPE Loss: 20.6626\n",
            "Fine-Tuning Epoch [12/30], Average SMAPE Loss: 20.5472\n",
            "Fine-Tuning Epoch [13/30], Average SMAPE Loss: 20.4289\n",
            "Fine-Tuning Epoch [14/30], Average SMAPE Loss: 20.3042\n",
            "Fine-Tuning Epoch [15/30], Average SMAPE Loss: 20.1544\n",
            "Fine-Tuning Epoch [16/30], Average SMAPE Loss: 20.1267\n",
            "Fine-Tuning Epoch [17/30], Average SMAPE Loss: 19.9954\n",
            "Fine-Tuning Epoch [18/30], Average SMAPE Loss: 19.9513\n",
            "Fine-Tuning Epoch [19/30], Average SMAPE Loss: 19.8635\n",
            "Fine-Tuning Epoch [20/30], Average SMAPE Loss: 19.8069\n",
            "Fine-Tuning Epoch [21/30], Average SMAPE Loss: 19.7534\n",
            "Fine-Tuning Epoch [22/30], Average SMAPE Loss: 19.6350\n",
            "Fine-Tuning Epoch [23/30], Average SMAPE Loss: 19.6394\n",
            "Fine-Tuning Epoch [24/30], Average SMAPE Loss: 19.4476\n",
            "Fine-Tuning Epoch [25/30], Average SMAPE Loss: 19.4994\n",
            "Fine-Tuning Epoch [26/30], Average SMAPE Loss: 19.3934\n",
            "Fine-Tuning Epoch [27/30], Average SMAPE Loss: 19.3192\n",
            "Fine-Tuning Epoch [28/30], Average SMAPE Loss: 19.2954\n",
            "Fine-Tuning Epoch [29/30], Average SMAPE Loss: 19.3194\n",
            "Fine-Tuning Epoch [30/30], Average SMAPE Loss: 19.2831\n",
            "\n",
            "--- FINE-TUNING COMPLETE ---\n",
            "Total fine-tuning time: 5.07 minutes.\n",
            "\n",
            "--- Generating Final Fine-Tuned Submission File ---\n",
            "\n",
            "Submission file 'submission_mlp_finetuned.csv' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Submission**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L93Bw3kwL4Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 7: GENERATE SUBMISSION (DEFINITIVE CRASH & ERROR FIX v2)\n",
        "# =============================================================================\n",
        "# This version fixes the .clip() typo and correctly handles NaN/inf values.\n",
        "\n",
        "print(\"\\n--- Generating Final Submission File (Definitive Fix v2) ---\")\n",
        "\n",
        "# The 'model' is already trained and in memory. We will re-run the prediction\n",
        "# and cleaning process to be safe.\n",
        "\n",
        "model.eval()\n",
        "final_predictions = []\n",
        "batch_size = 512\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, X_test_sparse.shape[0], batch_size):\n",
        "        X_batch_sparse = X_test_sparse[i:i + batch_size]\n",
        "        X_batch_dense = torch.tensor(X_batch_sparse.toarray(), dtype=torch.float32).to(device)\n",
        "        outputs = model(X_batch_dense)\n",
        "        final_predictions.append(outputs.cpu())\n",
        "\n",
        "test_predictions_log = torch.cat(final_predictions).numpy()\n",
        "final_predictions = np.expm1(test_predictions_log)\n",
        "\n",
        "print(\"Predictions generated successfully.\")\n",
        "\n",
        "# --- SAFETY CHECKS ---\n",
        "if np.isnan(final_predictions).any() or np.isinf(final_predictions).any():\n",
        "    print(\"WARNING: Invalid values (NaN or infinity) found in predictions.\")\n",
        "    median_pred = np.nanmedian(final_predictions)\n",
        "    final_predictions = np.nan_to_num(final_predictions, nan=median_pred, posinf=median_pred, neginf=median_pred)\n",
        "    print(f\"Replaced invalid values with the median prediction: {median_pred:.4f}\")\n",
        "\n",
        "# --- THE FIX: Use min=0 instead of lower=0 ---\n",
        "final_predictions = final_predictions.clip(min=0)\n",
        "print(\"Clipped all predictions to be non-negative.\")\n",
        "\n",
        "# --- CREATE AND SAVE THE SUBMISSION FILE ---\n",
        "submission_df_mlp = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': final_predictions.flatten()\n",
        "})\n",
        "\n",
        "print(f\"\\nSubmission file shape: {submission_df_mlp.shape}\")\n",
        "print(f\"Number of rows in original test set: {len(test_df)}\")\n",
        "if len(submission_df_mlp) != len(test_df):\n",
        "    print(\"ERROR: Row count mismatch!\")\n",
        "else:\n",
        "    print(\"Row count check passed.\")\n",
        "\n",
        "submission_df_mlp.to_csv(\"submission_mlp_final_v3.csv\", index=False)\n",
        "print(\"\\nSubmission file 'submission_mlp_final_v3.csv' created successfully.\")\n",
        "print(\"This version is robust and should evaluate correctly.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "sBT0uwwNeZA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3336f6d4-aebf-433f-c406-f1eb4391df0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Final Submission File (Definitive Fix v2) ---\n",
            "Predictions generated successfully.\n",
            "WARNING: Invalid values (NaN or infinity) found in predictions.\n",
            "Replaced invalid values with the median prediction: 13.3140\n",
            "Clipped all predictions to be non-negative.\n",
            "\n",
            "Submission file shape: (75000, 2)\n",
            "Number of rows in original test set: 75000\n",
            "Row count check passed.\n",
            "\n",
            "Submission file 'submission_mlp_final_v3.csv' created successfully.\n",
            "This version is robust and should evaluate correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSHQ9UnGeY91"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}